{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset, load_metric\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "import CsvConverter as Conv\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T11:48:56.503071400Z",
     "start_time": "2024-05-30T11:48:36.494732400Z"
    }
   },
   "id": "7dee6fb31143df24"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "user_stories_df = pd.read_csv('../DB_GroundTruth/userStories.csv', delimiter=';')\n",
    "user_stories = user_stories_df['user_stories'].tolist()\n",
    "df = pd.read_csv('D:/Thesis/DB/datasets/skills.csv', header=None, encoding='ISO-8859-1')\n",
    "labels = df[0].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T11:48:56.517601100Z",
     "start_time": "2024-05-30T11:48:56.493886700Z"
    }
   },
   "id": "4fc37699e4844f01"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T11:48:56.545075Z",
     "start_time": "2024-05-30T11:48:56.517601100Z"
    }
   },
   "id": "31e9d7966a332671"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "model_name = \"facebook/bart-large-mnli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T11:49:00.487532800Z",
     "start_time": "2024-05-30T11:48:56.545075Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_new_tokens(sentences, vocabulary):\n",
    "    vocab_set = set(vocabulary)\n",
    "    cleaned_words = (re.sub(r\"[.'\\s\\n]+|('\\s)\", \"\", word).lower().strip() for sentence in sentences for word in\n",
    "                     sentence.split())\n",
    "    return [word for word in cleaned_words if word not in vocab_set and word]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T11:49:00.492122700Z",
     "start_time": "2024-05-30T11:49:00.490119Z"
    }
   },
   "id": "7cdd7dc96762187c"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def word_count(word_list):\n",
    "    return Counter(word_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T11:49:00.498151600Z",
     "start_time": "2024-05-30T11:49:00.493123Z"
    }
   },
   "id": "69437d4fecb1fa74"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def tokenize(data):\n",
    "    data['hypothesis'] = data['hypothesis'].astype(\"str\")\n",
    "    data['premise'] = data['premise'].astype(\"str\")\n",
    "    data['premise'] = data['premise'].str.replace(\"'\", '')\n",
    "    sentences = data['hypothesis'].to_list() + data['premise'].to_list()\n",
    "    sentences = [sentence.replace(\",\", \"\") for sentence in sentences]\n",
    "    \n",
    "    vocabulary = tokenizer.get_vocab().keys()\n",
    "    tokens_to_add = get_new_tokens(sentences, vocabulary)\n",
    "    words = word_count(tokens_to_add)\n",
    "    # Initialize an empty list to store new tokens + Loop through the words and their counts\n",
    "    new_tokens = []\n",
    "    for key, value in words.items():\n",
    "        if value > 10 and len(key) > 2:\n",
    "            new_tokens.append(key)\n",
    "    tokenizer.add_tokens(new_tokens)\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T11:49:00.503197500Z",
     "start_time": "2024-05-30T11:49:00.497145100Z"
    }
   },
   "id": "987ec13a62e57310"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def synth_to_nli(data):\n",
    "    data.rename(columns={'user_stories': 'hypothesis', 'skills': 'premise'}, inplace=True)\n",
    "    data['class'] = 0\n",
    "\n",
    "    tokenize(data)\n",
    "    return data\n",
    "\n",
    "df = synth_to_nli(user_stories_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T11:49:01.101183400Z",
     "start_time": "2024-05-30T11:49:00.503197500Z"
    }
   },
   "id": "871785328c8a7865"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def shuffle_df(old_df: pd.DataFrame, cycles: int = 1) -> pd.DataFrame:\n",
    "    np.random.seed(42)\n",
    "    for i in range(cycles):\n",
    "        new_df = old_df.sample(frac=1).reset_index(drop=True)\n",
    "        return new_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T11:49:01.106221900Z",
     "start_time": "2024-05-30T11:49:01.102839600Z"
    }
   },
   "id": "10bb994e77f4286b"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def create_input_sequence(sample):\n",
    "    text = sample[\"premise\"]\n",
    "    hypothesis = sample['hypothesis']\n",
    "    nli_label = sample['class']\n",
    "\n",
    "    # Encoding the sequence using the tokenizer\n",
    "    encoded_sequence = tokenizer(text, hypothesis, truncation=True, padding='max_length')\n",
    "    # Assign label to the encoded sequence\n",
    "    encoded_sequence['labels'] = nli_label\n",
    "    # Decode the input_ids\n",
    "    encoded_sequence[\"input_sentence\"] = tokenizer.batch_decode(encoded_sequence.input_ids)\n",
    "    return encoded_sequence"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T11:49:01.109733900Z",
     "start_time": "2024-05-30T11:49:01.104857400Z"
    }
   },
   "id": "36339c22c01354cc"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/40 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7799d5841e97421ca33b69c37ddc393e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/60 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a079bb9eba5f441098e4ef7bbaf7dbcb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_size = 0.6\n",
    "train_data, test_data = train_test_split(df, test_size=test_size, random_state=42)\n",
    "train_shuffle_df = shuffle_df(train_data)\n",
    "test_shuffle_df = shuffle_df(test_data)\n",
    "\n",
    "# Create a Dataset object from the shuffled train DataFrame\n",
    "train = Dataset.from_pandas(train_shuffle_df)\n",
    "test = Dataset.from_pandas(test_shuffle_df)\n",
    "\n",
    "# Map the create_input_sequence function to the train and test datasets\n",
    "# This function encodes the data, adds labels, and generates input sentences\n",
    "train_dataset = train.map(create_input_sequence, batched=True, batch_size=1, remove_columns=[\"class\", \"premise\"])\n",
    "test_dataset = test.map(create_input_sequence, batched=True, batch_size=1, remove_columns=[\"class\", \"premise\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T11:49:01.596384200Z",
     "start_time": "2024-05-30T11:49:01.107733200Z"
    }
   },
   "id": "116b8e05c088d0db"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "#def compute_metrics(eval_pred):\n",
    "#    logits, labels = eval_pred\n",
    "#    predictions = np.argmax(logits, axis=-1)\n",
    "#    return metric.compute(predictions=predictions, references=labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T11:49:01.601480100Z",
     "start_time": "2024-05-30T11:49:01.598474300Z"
    }
   },
   "id": "d00f97d75e0afdba"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from transformers import EvalPrediction\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    # Extracting predictions from EvalPrediction object\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    # Obtaining the predicted classes\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "\n",
    "    # Calculating the ratio of predictions equals to 2 (assumed label)\n",
    "    ratio = np.mean(preds == 2)\n",
    "\n",
    "    # Dictionary to store computed metrics\n",
    "    metric_result = {}\n",
    "\n",
    "    # Loading evaluation metrics\n",
    "    metric_f1 = load_metric(\"f1\", trust_remote_code=True)\n",
    "    metric_precision = load_metric(\"precision\", trust_remote_code=True)\n",
    "    metric_recall = load_metric(\"recall\", trust_remote_code=True)\n",
    "    metric_acc = load_metric(\"accuracy\", trust_remote_code=True)\n",
    "\n",
    "    # Computing various metrics\n",
    "    metric_result[\"accuracy\"] = metric_acc.compute(predictions=preds, references=p.label_ids)[\"accuracy\"]\n",
    "    metric_result[\"precision\"] = metric_precision.compute(predictions=preds, references=p.label_ids, average='macro')['precision']\n",
    "    metric_result[\"recall\"] = metric_recall.compute(predictions=preds, references=p.label_ids, average='macro')[\"recall\"]\n",
    "    metric_result[\"f1\"] = metric_f1.compute(predictions=preds, references=p.label_ids, average='macro')[\"f1\"]\n",
    "    metric_result[\"ratio\"] = ratio\n",
    "\n",
    "    return metric_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T11:49:01.606988600Z",
     "start_time": "2024-05-30T11:49:01.601480100Z"
    }
   },
   "id": "21df9c2eefd8295"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()\n",
    "model.config.use_cache = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T11:49:01.611659500Z",
     "start_time": "2024-05-30T11:49:01.606988600Z"
    }
   },
   "id": "d73f1874d8dc8035"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "'training_args = TrainingArguments(\\n    output_dir=\"test_trainer\",\\n    eval_strategy=\"epoch\",\\n    per_device_train_batch_size=16,\\n    per_device_eval_batch_size=16,\\n    num_train_epochs=5,\\n    learning_rate=2e-5,\\n    weight_decay=0.01,\\n)'"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    ")\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T11:49:01.616388300Z",
     "start_time": "2024-05-30T11:49:01.610658800Z"
    }
   },
   "id": "4ca132e8a940620a"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\",  # Output directory\n",
    "    logging_dir=\"test_trainer/logs\",  # Output directory for logging\n",
    "    num_train_epochs=1,  # Total number of training epochs\n",
    "    per_device_train_batch_size=16,  # Batch size per device during training\n",
    "    per_device_eval_batch_size=2,  # Batch size for evaluation\n",
    "    warmup_steps=4,  # Number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,  # Strength of weight decay\n",
    "    gradient_accumulation_steps=2,  # The number of steps whose gradients are accumulated\n",
    "    learning_rate=2e-05,  # Controls the magnitude of updates to the model weights\n",
    "    warmup_ratio=0.06,  # Represents the proportion of training steps\n",
    "    label_smoothing_factor=0.1,  # Regularization technique to prevent the model from becoming overconfident\n",
    "    eval_strategy='steps',  # Frequency or timing of evaluating\n",
    "    logging_strategy='steps',  # Frequency or timing of logging\n",
    "    logging_steps=10,  # Frequency or timing of logging\n",
    "    eval_steps=10,  # Frequency or timing of evaluating\n",
    "    logging_first_step=True,\n",
    "    do_eval=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T11:49:01.651661300Z",
     "start_time": "2024-05-30T11:49:01.613873Z"
    }
   },
   "id": "4c4bea396e2c3f3"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T11:49:02.074984100Z",
     "start_time": "2024-05-30T11:49:01.627749200Z"
    }
   },
   "id": "868904be129ec2a8"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Thesis\\venv\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:597: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/30 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Coco\\AppData\\Local\\Temp\\ipykernel_28640\\3683961183.py:17: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric_f1 = load_metric(\"f1\", trust_remote_code=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mismatch in the number of predictions (3) and references (60)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Thesis\\venv\\Lib\\site-packages\\transformers\\trainer.py:3572\u001B[0m, in \u001B[0;36mTrainer.evaluate\u001B[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[0;32m   3569\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m   3571\u001B[0m eval_loop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprediction_loop \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39muse_legacy_prediction_loop \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluation_loop\n\u001B[1;32m-> 3572\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43meval_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3573\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3574\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdescription\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mEvaluation\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3575\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001B[39;49;00m\n\u001B[0;32m   3576\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# self.args.prediction_loss_only\u001B[39;49;00m\n\u001B[0;32m   3577\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprediction_loss_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   3578\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3579\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3580\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3582\u001B[0m total_batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39meval_batch_size \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mworld_size\n\u001B[0;32m   3583\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_key_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_jit_compilation_time\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output\u001B[38;5;241m.\u001B[39mmetrics:\n",
      "File \u001B[1;32mD:\\Thesis\\venv\\Lib\\site-packages\\transformers\\trainer.py:3854\u001B[0m, in \u001B[0;36mTrainer.evaluation_loop\u001B[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[0;32m   3850\u001B[0m         metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_metrics(\n\u001B[0;32m   3851\u001B[0m             EvalPrediction(predictions\u001B[38;5;241m=\u001B[39mall_preds, label_ids\u001B[38;5;241m=\u001B[39mall_labels, inputs\u001B[38;5;241m=\u001B[39mall_inputs)\n\u001B[0;32m   3852\u001B[0m         )\n\u001B[0;32m   3853\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 3854\u001B[0m         metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mEvalPrediction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mall_preds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mall_labels\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3855\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m metrics \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   3856\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m {}\n",
      "Cell \u001B[1;32mIn[13], line 23\u001B[0m, in \u001B[0;36mcompute_metrics\u001B[1;34m(p)\u001B[0m\n\u001B[0;32m     20\u001B[0m metric_acc \u001B[38;5;241m=\u001B[39m load_metric(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m, trust_remote_code\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# Computing various metrics\u001B[39;00m\n\u001B[1;32m---> 23\u001B[0m metric_result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mmetric_acc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreferences\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_ids\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m     24\u001B[0m metric_result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprecision\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m metric_precision\u001B[38;5;241m.\u001B[39mcompute(predictions\u001B[38;5;241m=\u001B[39mpreds, references\u001B[38;5;241m=\u001B[39mp\u001B[38;5;241m.\u001B[39mlabel_ids, average\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmacro\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprecision\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     25\u001B[0m metric_result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrecall\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m metric_recall\u001B[38;5;241m.\u001B[39mcompute(predictions\u001B[38;5;241m=\u001B[39mpreds, references\u001B[38;5;241m=\u001B[39mp\u001B[38;5;241m.\u001B[39mlabel_ids, average\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmacro\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrecall\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32mD:\\Thesis\\venv\\Lib\\site-packages\\datasets\\metric.py:444\u001B[0m, in \u001B[0;36mMetric.compute\u001B[1;34m(self, predictions, references, **kwargs)\u001B[0m\n\u001B[0;32m    441\u001B[0m compute_kwargs \u001B[38;5;241m=\u001B[39m {k: kwargs[k] \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m kwargs \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures}\n\u001B[0;32m    443\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(v \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m inputs\u001B[38;5;241m.\u001B[39mvalues()):\n\u001B[1;32m--> 444\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    445\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_finalize()\n\u001B[0;32m    447\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcache_file_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Thesis\\venv\\Lib\\site-packages\\datasets\\metric.py:521\u001B[0m, in \u001B[0;36mMetric.add_batch\u001B[1;34m(self, predictions, references, **kwargs)\u001B[0m\n\u001B[0;32m    514\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    515\u001B[0m     error_msg \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    516\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPredictions and/or references don\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt match the expected format.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    517\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected format: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m,\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    518\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInput predictions: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msummarize_if_long_list(predictions)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m,\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    519\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInput references: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msummarize_if_long_list(references)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    520\u001B[0m     )\n\u001B[1;32m--> 521\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(error_msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: Mismatch in the number of predictions (3) and references (60)"
     ]
    }
   ],
   "source": [
    "trainer.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T11:49:09.671274400Z",
     "start_time": "2024-05-30T11:49:02.079413800Z"
    }
   },
   "id": "6397e737d8a58c25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T11:49:09.673276300Z",
     "start_time": "2024-05-30T11:49:09.672274800Z"
    }
   },
   "id": "f0ce14d92ab4883a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-30T11:49:09.673276300Z"
    }
   },
   "id": "3490ff0933eeb0a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create Pipeline with the new model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c08dac08f8aae47"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create new pipeline object with our fine-tuned model and tokenizer\n",
    "model.config.use_cache = True\n",
    "classifier_after = pipeline('zero-shot-classification', model=model, tokenizer=tokenizer, device=device)\n",
    "after_results = classifier_after(user_stories, labels, multi_label=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T11:49:09.674781700Z",
     "start_time": "2024-05-30T11:49:09.673276300Z"
    }
   },
   "id": "1b36bf38181d6364"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_name = \"bart\"\n",
    "split = str(test_size).replace(\".\",\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-30T11:49:09.674781700Z"
    }
   },
   "id": "8721406e005b6138"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(f\"output_txt/{model_name}_{split}_result_after.txt\", 'w') as f:\n",
    "    for story, result in zip(user_stories, after_results):\n",
    "        f.write(f\"Story: {story}\\n\")\n",
    "        for label, score in zip(result['labels'], result['scores']):\n",
    "            f.write(f\"- {label}: {score:.2f}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T11:49:09.675787300Z",
     "start_time": "2024-05-30T11:49:09.675787300Z"
    }
   },
   "id": "e937c71119f19bbe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "file_dir = os.getcwd()\n",
    "#dir = os.path.abspath(\"\")\n",
    "csv = Conv.CsvConverter(os.path.join(file_dir, 'output_txt',f'{model_name}_{split}_result_after.txt'),\n",
    "                        os.path.join(file_dir, 'output_csv', f'{model_name}_{split}_result_after.csv'),\n",
    "                        'Story')\n",
    "csv.convert()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-30T11:49:09.676788600Z"
    }
   },
   "id": "13d439cfa2b1a884"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-30T11:49:09.677787200Z"
    }
   },
   "id": "578723755d650216"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

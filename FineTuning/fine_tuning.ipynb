{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset, load_metric\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments, EvalPrediction\n",
    "from transformers import pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T09:34:43.349313200Z",
     "start_time": "2024-05-29T09:34:38.000715200Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model_name = 'bart'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T09:34:43.353225500Z",
     "start_time": "2024-05-29T09:34:43.351714300Z"
    }
   },
   "id": "4df0afd8561fd59d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Code inspired from  https://medium.com/@igafni21/smartshot-fine-tuning-zero-shot-classification-models-with-nli-a990f5478b4f"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "726fb5f90ec65e04"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Thesis\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "bart = \"facebook/bart-large-mnli\"\n",
    "deberta_base = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "dir = \"/model\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "classifier_before = pipeline('zero-shot-classification', device=device, model=bart)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T09:34:46.787649500Z",
     "start_time": "2024-05-29T09:34:43.353225500Z"
    }
   },
   "id": "95d890b0b3713b19"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "model = classifier_before.model\n",
    "tokenizer = classifier_before.tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T09:34:46.794252300Z",
     "start_time": "2024-05-29T09:34:46.787649500Z"
    }
   },
   "id": "cf62d6b9d6e78b55"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "user_stories_df = pd.read_csv('../DB_GroundTruth/userStories.csv', delimiter=';')\n",
    "user_stories = user_stories_df['user_stories'].tolist()\n",
    "df = pd.read_csv('D:/Thesis/DB/datasets/skills.csv', header=None, encoding='ISO-8859-1')\n",
    "labels = df[0].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T09:34:46.819169700Z",
     "start_time": "2024-05-29T09:34:46.791165100Z"
    }
   },
   "id": "cb4b43f2f0608978"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_new_tokens(sentences, vocabulary):\n",
    "    vocab_set = set(vocabulary)\n",
    "    cleaned_words = (re.sub(r\"[.'\\s\\n]+|('\\s)\", \"\", word).lower().strip() for sentence in sentences for word in\n",
    "                     sentence.split())\n",
    "    return [word for word in cleaned_words if word not in vocab_set and word]\n",
    "\n",
    "\n",
    "def word_count(word_list):\n",
    "    return Counter(word_list)\n",
    "\n",
    "\n",
    "def tokenize(df):\n",
    "    sentences = df['hypothesis'].to_list() + df['premise'].to_list()\n",
    "    vocabulary = tokenizer.get_vocab().keys()\n",
    "    tokens_to_add = get_new_tokens(sentences, vocabulary)\n",
    "    words = word_count(tokens_to_add)\n",
    "    # Initialize an empty list to store new tokens + Loop through the words and their counts\n",
    "    new_tokens = []\n",
    "    for key, value in words.items():\n",
    "        if value > 10 and len(key) > 2:\n",
    "            new_tokens.append(key)\n",
    "    tokenizer.add_tokens(new_tokens)\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T09:34:46.819169700Z",
     "start_time": "2024-05-29T09:34:46.816458500Z"
    }
   },
   "id": "64c6c4a1314f550e"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def synth_to_nli(df):\n",
    "    df.rename(columns={'user_stories': 'hypothesis', 'skills': 'premise'}, inplace=True)\n",
    "    df['class'] = 0\n",
    "    df['hypothesis'] = df['hypothesis'].astype(\"str\")\n",
    "    df['premise'] = df['premise'].astype(\"str\")\n",
    "    #df['premise'] = df['premise'].str.replace(\"'\", '')\n",
    "    tokenize(df)\n",
    "    return df\n",
    "\n",
    "df = synth_to_nli(user_stories_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T09:34:46.891324900Z",
     "start_time": "2024-05-29T09:34:46.819169700Z"
    }
   },
   "id": "c4c1e18cd7a6fa4"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def shuffle_df(old_df: pd.DataFrame, cycles: int = 1) -> pd.DataFrame:\n",
    "    np.random.seed(42)\n",
    "    for i in range(cycles):\n",
    "        new_df = old_df.sample(frac=1).reset_index(drop=True)\n",
    "        return new_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T09:34:46.898609500Z",
     "start_time": "2024-05-29T09:34:46.892833500Z"
    }
   },
   "id": "1ab25f47953f85b"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def create_input_sequence(sample):\n",
    "    text = sample[\"premise\"]\n",
    "    hypothesis = sample['hypothesis']\n",
    "\n",
    "    label = sample['class']\n",
    "\n",
    "    # Encoding the sequence using the tokenizer\n",
    "    encoded_sequence = tokenizer(text, hypothesis, truncation=True, padding='max_length')\n",
    "    # Assign label to the encoded sequence\n",
    "    encoded_sequence['labels'] = label\n",
    "    # Decode the input_ids\n",
    "    encoded_sequence[\"input_sentence\"] = tokenizer.batch_decode(encoded_sequence.input_ids)\n",
    "    return encoded_sequence"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T09:34:46.898609500Z",
     "start_time": "2024-05-29T09:34:46.896204100Z"
    }
   },
   "id": "fa706aa65d9852c9"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/20 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "480fb80ed65d4873a9bb7ed83fd3ac10"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/80 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d066c8e7399e497f8bb5ba5fc6ec6530"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "train_data, test_data = train_test_split(df, test_size=0.8, random_state=42)\n",
    "train_shuffle_df = shuffle_df(train_data)\n",
    "test_shuffle_df = shuffle_df(test_data)\n",
    "\n",
    "# Create a Dataset object from the shuffled train DataFrame\n",
    "train = Dataset.from_pandas(train_shuffle_df)\n",
    "test = Dataset.from_pandas(test_shuffle_df)\n",
    "\n",
    "# Map the create_input_sequence function to the train and test datasets\n",
    "# This function encodes the data, adds labels, and generates input sentences\n",
    "train_dataset = train.map(create_input_sequence, batched=True, batch_size=1, remove_columns=[\"class\", \"premise\"])\n",
    "test_dataset = test.map(create_input_sequence, batched=True, batch_size=1, remove_columns=[\"class\", \"premise\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T09:34:47.354901300Z",
     "start_time": "2024-05-29T09:34:46.898609500Z"
    }
   },
   "id": "dd51a3059f6f0fc5"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def compute_metrics(p: EvalPrediction):\n",
    "    # Extracting predictions from EvalPrediction object\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    # Obtaining the predicted classes\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "\n",
    "    # Calculating the ratio of predictions equal to 2 (assumed label)\n",
    "    ratio = np.mean(preds == 2)\n",
    "\n",
    "    # Dictionary to store computed metrics\n",
    "    result = {}\n",
    "\n",
    "    # Loading evaluation metrics\n",
    "    metric_f1 = load_metric(\"f1\")\n",
    "    metric_precision = load_metric(\"precision\")\n",
    "    metric_recall = load_metric(\"recall\")\n",
    "    metric_acc = load_metric(\"accuracy\")\n",
    "\n",
    "    # Computing various metrics\n",
    "    result[\"accuracy\"] = metric_acc.compute(predictions=preds, references=p.label_ids)[\"accuracy\"]\n",
    "    result[\"precision\"] = metric_precision.compute(predictions=preds, references=p.label_ids, average='macro')[\n",
    "        'precision']\n",
    "    result[\"recall\"] = metric_recall.compute(predictions=preds, references=p.label_ids, average='macro')[\"recall\"]\n",
    "    result[\"f1\"] = metric_f1.compute(predictions=preds, references=p.label_ids, average='macro')[\"f1\"]\n",
    "    result[\"ratio\"] = ratio\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T09:34:47.361729700Z",
     "start_time": "2024-05-29T09:34:47.355906400Z"
    }
   },
   "id": "bdde7bff80513138"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=dir,  # Output directory\n",
    "    logging_dir=dir + \"/logs\",  # Output directory for logging\n",
    "    num_train_epochs=1,  # Total number of training epochs\n",
    "    per_device_train_batch_size=32,  # Batch size per device during training\n",
    "    per_device_eval_batch_size=2,  # Batch size for evaluation\n",
    "    warmup_steps=4,  # Number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,  # Strength of weight decay\n",
    "    gradient_accumulation_steps=2,  # The number of steps whose gradients are accumulated\n",
    "    learning_rate=2e-05,  # Controls the magnitude of updates to the model weights\n",
    "    warmup_ratio=0.06,  # Represents the proportion of training steps\n",
    "    label_smoothing_factor=0.1,  # Regularization technique to prevent the model from becoming overconfident\n",
    "    eval_strategy='steps',  # Frequency or timing of evaluating\n",
    "    logging_strategy='steps',  # Frequency or timing of logging\n",
    "    logging_steps=10,  # Frequency or timing of logging\n",
    "    eval_steps=10,  # Frequency or timing of evaluating\n",
    "    logging_first_step=True,\n",
    "    do_eval=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T09:34:47.368151600Z",
     "start_time": "2024-05-29T09:34:47.358729700Z"
    }
   },
   "id": "fb442809166347cf"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()\n",
    "model.config.use_cache = False\n",
    "trainer = Trainer(\n",
    "    model=model,  # The instantiated model to be trained\n",
    "    args=training_args,  # Training arguments, defined above\n",
    "    compute_metrics=compute_metrics,  # A function to compute the metrics\n",
    "    train_dataset=train_dataset,  # Training dataset\n",
    "    eval_dataset=test_dataset  # Evaluation dataset\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T09:34:47.425187300Z",
     "start_time": "2024-05-29T09:34:47.367152Z"
    }
   },
   "id": "2dca57c31869e59e"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Thesis\\venv\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:597: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/40 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Coco\\AppData\\Local\\Temp\\ipykernel_28296\\1671836352.py:14: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric_f1 = load_metric(\"f1\")\n",
      "D:\\Thesis\\venv\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "D:\\Thesis\\venv\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for precision contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/precision/precision.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "D:\\Thesis\\venv\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for recall contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/recall/recall.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "D:\\Thesis\\venv\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "D:\\Thesis\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\Thesis\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'eval_loss': 7.271732330322266,\n 'eval_accuracy': 0.0,\n 'eval_precision': 0.0,\n 'eval_recall': 0.0,\n 'eval_f1': 0.0,\n 'eval_ratio': 0.0,\n 'eval_runtime': 27.8657,\n 'eval_samples_per_second': 2.871,\n 'eval_steps_per_second': 1.435}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T09:35:15.348026Z",
     "start_time": "2024-05-29T09:34:47.426186Z"
    }
   },
   "id": "564be399f3a0901b"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2/1 : < :, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=1, training_loss=3.1530885696411133, metrics={'train_runtime': 4.7089, 'train_samples_per_second': 4.247, 'train_steps_per_second': 0.212, 'total_flos': 43471444746240.0, 'train_loss': 3.1530885696411133, 'epoch': 1.0})"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T09:35:20.304249800Z",
     "start_time": "2024-05-29T09:35:15.347638400Z"
    }
   },
   "id": "10a01a7995c18dde"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "BartForSequenceClassification(\n  (model): BartModel(\n    (shared): Embedding(50282, 1024)\n    (encoder): BartEncoder(\n      (embed_tokens): Embedding(50282, 1024)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x BartEncoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): BartDecoder(\n      (embed_tokens): Embedding(50282, 1024)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x BartDecoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (classification_head): BartClassificationHead(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0.0, inplace=False)\n    (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n  )\n)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T09:35:20.317762Z",
     "start_time": "2024-05-29T09:35:20.261303200Z"
    }
   },
   "id": "f5888149ab9fd11a"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"model/bart_08\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T09:35:25.400061300Z",
     "start_time": "2024-05-29T09:35:20.266967600Z"
    }
   },
   "id": "ab90abfaf377576a"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\ndef plot_metrics(data):\\n    # Extract parameters\\n    parameters = data[0].keys()\\n\\n    # Plot each parameter in a separate graph\\n    num_plots = len(parameters) - 1  # Exclude 'Step'\\n    fig, axes = plt.subplots(num_plots, 1, figsize=(8, num_plots*2))\\n\\n    for i, param in enumerate(parameters):\\n        if param == 'Step':\\n            continue\\n\\n        ax = axes[i - 1] if num_plots > 1 else axes\\n        ax.plot([d['Step'] for d in data], [d[param] for d in data], marker='o', label=param)\\n        ax.set_xlabel('Step')\\n        ax.set_ylabel(param)\\n        ax.set_title(f'Plot of {param}')\\n        ax.legend()\\n\\n    plt.tight_layout()\\n    plt.show()\\n\\nplot_metrics(data)\""
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def plot_metrics(data):\n",
    "    # Extract parameters\n",
    "    parameters = data[0].keys()\n",
    "\n",
    "    # Plot each parameter in a separate graph\n",
    "    num_plots = len(parameters) - 1  # Exclude 'Step'\n",
    "    fig, axes = plt.subplots(num_plots, 1, figsize=(8, num_plots*2))\n",
    "\n",
    "    for i, param in enumerate(parameters):\n",
    "        if param == 'Step':\n",
    "            continue\n",
    "\n",
    "        ax = axes[i - 1] if num_plots > 1 else axes\n",
    "        ax.plot([d['Step'] for d in data], [d[param] for d in data], marker='o', label=param)\n",
    "        ax.set_xlabel('Step')\n",
    "        ax.set_ylabel(param)\n",
    "        ax.set_title(f'Plot of {param}')\n",
    "        ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics(data)\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T09:35:25.401212900Z",
     "start_time": "2024-05-29T09:35:25.395547400Z"
    }
   },
   "id": "aeec8c270176a804"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Create new pipeline object with our finetuned model and tokenizer\n",
    "model.config.use_cache = True\n",
    "classifier_after = pipeline('zero-shot-classification', model=model, tokenizer=tokenizer, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T09:35:25.403228900Z",
     "start_time": "2024-05-29T09:35:25.400061300Z"
    }
   },
   "id": "4c208400eff1786d"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "after_results = classifier_after(user_stories, labels, multi_label=True)\n",
    "#to_txt(results, \"after\")\n",
    "with open(f\"{model_name}_08_result_after.txt\", 'w') as f:\n",
    "    for story, result in zip(user_stories, after_results):\n",
    "        f.write(f\"Story: {story}\\n\")\n",
    "        for label, score in zip(result['labels'], result['scores']):\n",
    "            f.write(f\"- {label}: {score:.2f}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T09:38:10.841377200Z",
     "start_time": "2024-05-29T09:35:25.403228900Z"
    }
   },
   "id": "80acd8a62bb2b8d2"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Thesis\\FineTuning\n"
     ]
    }
   ],
   "source": [
    "import CsvConverter as conv\n",
    "import os\n",
    "print(os.getcwd())\n",
    "dir = os.getcwd()\n",
    "#dir = os.path.abspath(\"\")\n",
    "csv = conv.CsvConverter(os.path.join(dir, f'{model_name}_08_result_after.txt'),\n",
    "                        os.path.join(dir, f'{model_name}_08_result_after.csv'),\n",
    "                        'Story')\n",
    "csv.convert()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T09:38:10.875903300Z",
     "start_time": "2024-05-29T09:38:10.842381200Z"
    }
   },
   "id": "43006b016a061c31"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T09:38:10.907182300Z",
     "start_time": "2024-05-29T09:38:10.876566800Z"
    }
   },
   "id": "c179a39763031fee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

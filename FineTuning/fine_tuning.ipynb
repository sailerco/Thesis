{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset, load_metric\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "import CsvConverter as Conv\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:26.947281100Z",
     "start_time": "2024-08-23T07:26:17.466534300Z"
    }
   },
   "id": "7dee6fb31143df24"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Configure Parameters and Name"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e87cf948e273856"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model_name = \"deberta\"\n",
    "\n",
    "train_batch = 32\n",
    "eval_batch = 32\n",
    "lr = 2e-05\n",
    "eps = 6\n",
    "wd = 0.06\n",
    "warm_ratio = 0.1\n",
    "\n",
    "freeze = False\n",
    "hypothesis_template_available = False\n",
    "\n",
    "test_size = 0.8"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:26.947784400Z",
     "start_time": "2024-08-23T07:26:26.947281100Z"
    }
   },
   "id": "8e34856d8ecdba6a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Generate config based on conditions\n",
    "if hypothesis_template_available:\n",
    "    config = f\"{str(test_size).replace('.', '')}_HP_{eps}_{lr}_{train_batch}{eval_batch}_{warm_ratio}_{wd}\"\n",
    "elif freeze:\n",
    "    config = f\"{str(test_size).replace('.', '')}_freeze_{eps}_{lr}_{train_batch}{eval_batch}_{warm_ratio}_{wd}\"\n",
    "else:\n",
    "    config = f\"{str(test_size).replace('.', '')}_{eps}_{lr}_{train_batch}{eval_batch}_{warm_ratio}_{wd}\"\n",
    "\n",
    "# Final model configuration name\n",
    "model_config_name = f\"{model_name}_{config}\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:26.957870Z",
     "start_time": "2024-08-23T07:26:26.949294200Z"
    }
   },
   "id": "56fe0e34913c01ce"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deberta_1_08_6_2e-05_3232_0.1_0.06\n"
     ]
    }
   ],
   "source": [
    "print(model_config_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:26.972023200Z",
     "start_time": "2024-08-23T07:26:26.957870Z"
    }
   },
   "id": "e90f1a62e8fa9219"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:27.014824600Z",
     "start_time": "2024-08-23T07:26:26.971021500Z"
    }
   },
   "id": "31e9d7966a332671"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "user_stories_df = pd.read_csv('../Classification_Synth/userStories.csv', delimiter=';')\n",
    "user_stories = user_stories_df['user_stories'].tolist()\n",
    "df = pd.read_csv('../DB/datasets/skills.csv', header=None, encoding='ISO-8859-1')\n",
    "labels = df[0].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:27.022898700Z",
     "start_time": "2024-08-23T07:26:26.993995600Z"
    }
   },
   "id": "4fc37699e4844f01"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "user_stories_df['skills'] = user_stories_df['skills'].apply(lambda x: [i.strip().replace(\"'\", \"\") for i in x.split(\",\")])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:27.022898700Z",
     "start_time": "2024-08-23T07:26:27.016774700Z"
    }
   },
   "id": "a5c5def21d5a0f1b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         user_stories  \\\n0   As a software developer at our company, I want...   \n1   As a software developer at our company, I want...   \n2   As a DevOps engineer at our company, I want to...   \n3   As a software engineer at our cryptocurrency d...   \n4   As a UI/UX designer and developer at our softw...   \n..                                                ...   \n95  As a DevOps engineer, I want to automate the b...   \n96  As a web developer, I want to implement a user...   \n97  As a QA engineer, I want to integrate Selenium...   \n98  As an IT administrator, I want to implement se...   \n99  As a database developer, I want to optimize ou...   \n\n                                               skills  \n0   [MQTT, IoT,  Sensor Integration,  Smart contra...  \n1   [Pandas, scikit-learn, Natural Language Proces...  \n2                                        [GCP, Azure]  \n3   [Cryptocurrency development, IoT, MQTT, Sensor...  \n4        [UI Design, Responsive Design, React Native]  \n..                                                ...  \n95                [GCP, Build Automation, Kubernetes]  \n96   [HTML, React, CSS, UI Design, Web Accessibility]  \n97                    [Agile Methodologies, Selenium]  \n98  [Troubleshooting, Active Directory, Security B...  \n99          [Microsoft SQL Server, RDBMS, MySQL, SQL]  \n\n[100 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_stories</th>\n      <th>skills</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>As a software developer at our company, I want...</td>\n      <td>[MQTT, IoT,  Sensor Integration,  Smart contra...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>As a software developer at our company, I want...</td>\n      <td>[Pandas, scikit-learn, Natural Language Proces...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>As a DevOps engineer at our company, I want to...</td>\n      <td>[GCP, Azure]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>As a software engineer at our cryptocurrency d...</td>\n      <td>[Cryptocurrency development, IoT, MQTT, Sensor...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>As a UI/UX designer and developer at our softw...</td>\n      <td>[UI Design, Responsive Design, React Native]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>As a DevOps engineer, I want to automate the b...</td>\n      <td>[GCP, Build Automation, Kubernetes]</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>As a web developer, I want to implement a user...</td>\n      <td>[HTML, React, CSS, UI Design, Web Accessibility]</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>As a QA engineer, I want to integrate Selenium...</td>\n      <td>[Agile Methodologies, Selenium]</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>As an IT administrator, I want to implement se...</td>\n      <td>[Troubleshooting, Active Directory, Security B...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>As a database developer, I want to optimize ou...</td>\n      <td>[Microsoft SQL Server, RDBMS, MySQL, SQL]</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_stories_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:27.042223100Z",
     "start_time": "2024-08-23T07:26:27.019900400Z"
    }
   },
   "id": "147b8e2ce09340e5"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "contras_df = pd.read_csv('truth.csv', index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:27.058074300Z",
     "start_time": "2024-08-23T07:26:27.037224400Z"
    }
   },
   "id": "ca7f6133a8f64dff"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Extract NaN skills for each column\n",
    "skills_nan = {col: contras_df.loc[contras_df[col].isna()].index.tolist() for col in contras_df.columns}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:27.122346500Z",
     "start_time": "2024-08-23T07:26:27.051746800Z"
    }
   },
   "id": "47016e54ed1b77bf"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Create a new DataFrame with the desired structure\n",
    "new_data = []\n",
    "for col, nan_indices in skills_nan.items():\n",
    "    #nan_indices = ', '.join(nan_indices)\n",
    "    new_data.append([col, nan_indices])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:27.122346500Z",
     "start_time": "2024-08-23T07:26:27.065033800Z"
    }
   },
   "id": "123fe4e365a4bf62"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "contras_df = pd.DataFrame(new_data, columns=['user_stories', 'skills'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:27.137363Z",
     "start_time": "2024-08-23T07:26:27.069296300Z"
    }
   },
   "id": "62791ad44eb80544"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "if model_name == \"bart\":\n",
    "    model_dir = \"facebook/bart-large-mnli\"\n",
    "else:\n",
    "    model_dir = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:28.346707300Z",
     "start_time": "2024-08-23T07:26:27.077315Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def get_new_tokens(sentences, vocabulary):\n",
    "    vocab_set = set(vocabulary)\n",
    "    cleaned_words = (re.sub(r\"[.'\\s\\n]+|('\\s)\", \"\", word).lower().strip() for sentence in sentences for word in\n",
    "                     sentence)\n",
    "    return [word for word in cleaned_words if word not in vocab_set and word]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:28.352219200Z",
     "start_time": "2024-08-23T07:26:28.348707700Z"
    }
   },
   "id": "7cdd7dc96762187c"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def word_count(word_list):\n",
    "    return Counter(word_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:28.360340700Z",
     "start_time": "2024-08-23T07:26:28.351219200Z"
    }
   },
   "id": "69437d4fecb1fa74"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def tokenize(data):\n",
    "    data['hypothesis'] = data['hypothesis'].astype(\"str\")\n",
    "    premises = []\n",
    "    for x in data['premise'].to_list():\n",
    "        premises.extend([item.strip() for item in x])\n",
    "    sentences = data['hypothesis'].to_list() + premises\n",
    "    \n",
    "    vocabulary = tokenizer.get_vocab().keys()\n",
    "    tokens_to_add = get_new_tokens(sentences, vocabulary)\n",
    "    words = word_count(tokens_to_add)\n",
    "    # Initialize an empty list to store new tokens + Loop through the words and their counts\n",
    "    new_tokens = []\n",
    "    for key, value in words.items():\n",
    "        if value > 10 and len(key) > 2:\n",
    "            new_tokens.append(key)\n",
    "    tokenizer.add_tokens(new_tokens)\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:28.366982600Z",
     "start_time": "2024-08-23T07:26:28.362341100Z"
    }
   },
   "id": "987ec13a62e57310"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def synth_to_nli(data, value):\n",
    "    data = data.copy()\n",
    "    data.rename(columns={'user_stories': 'hypothesis', 'skills': 'premise'}, inplace=True)\n",
    "    data['class'] = value\n",
    "    tokenize(data)\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:28.375152100Z",
     "start_time": "2024-08-23T07:26:28.367982200Z"
    }
   },
   "id": "dfe5d6d76115d004"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "if model_name == \"bart\":\n",
    "    df = synth_to_nli(user_stories_df, 2) # entailement\n",
    "    contras_df = synth_to_nli(contras_df, 0) # contradiction\n",
    "else:\n",
    "    df = synth_to_nli(user_stories_df, 0) # entailement\n",
    "    contras_df = synth_to_nli(contras_df, 2) # contradiction"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:29.325811800Z",
     "start_time": "2024-08-23T07:26:28.375152100Z"
    }
   },
   "id": "882a65f9d6e6bdab"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "df = df.explode('premise')\n",
    "contras_df = contras_df.explode('premise')\n",
    "contras_df = contras_df.sample(359)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:29.338794400Z",
     "start_time": "2024-08-23T07:26:29.326973Z"
    }
   },
   "id": "7d7df2f4de5604d8"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "df = pd.concat([df, contras_df], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:29.346514800Z",
     "start_time": "2024-08-23T07:26:29.338794400Z"
    }
   },
   "id": "36333a41993d494c"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:29.355986Z",
     "start_time": "2024-08-23T07:26:29.345511Z"
    }
   },
   "id": "56668a2dbf9d633c"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            hypothesis  \\\n0    As a software developer at our company, I want...   \n1    As a software developer at our company, I want...   \n2    As a software developer at our company, I want...   \n3    As a software developer at our company, I want...   \n4    As a software developer at our company, I want...   \n..                                                 ...   \n713  As a Software Architect with expertise in REST...   \n714  As a backend developer tasked with building a ...   \n715  As a cloud engineer, I want to design a scalab...   \n716  As a member of the development team, I want to...   \n717  As a data analyst at our software company, I w...   \n\n                          premise  class  \n0                            MQTT      0  \n1                             IoT      0  \n2              Sensor Integration      0  \n3                 Smart contracts      0  \n4                          Pandas      0  \n..                            ...    ...  \n713         System Administration      2  \n714                          CoAP      2  \n715                     UX Design      2  \n716                          HTML      2  \n717  UX/UI Design and Prototyping      2  \n\n[718 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hypothesis</th>\n      <th>premise</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>As a software developer at our company, I want...</td>\n      <td>MQTT</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>As a software developer at our company, I want...</td>\n      <td>IoT</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>As a software developer at our company, I want...</td>\n      <td>Sensor Integration</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>As a software developer at our company, I want...</td>\n      <td>Smart contracts</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>As a software developer at our company, I want...</td>\n      <td>Pandas</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>713</th>\n      <td>As a Software Architect with expertise in REST...</td>\n      <td>System Administration</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>714</th>\n      <td>As a backend developer tasked with building a ...</td>\n      <td>CoAP</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>715</th>\n      <td>As a cloud engineer, I want to design a scalab...</td>\n      <td>UX Design</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>716</th>\n      <td>As a member of the development team, I want to...</td>\n      <td>HTML</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>717</th>\n      <td>As a data analyst at our software company, I w...</td>\n      <td>UX/UI Design and Prototyping</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>718 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:29.367171800Z",
     "start_time": "2024-08-23T07:26:29.353733500Z"
    }
   },
   "id": "ba15315a0f0e1485"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def shuffle_df(old_df: pd.DataFrame, cycles: int = 1) -> pd.DataFrame:\n",
    "    np.random.seed(42)\n",
    "    for i in range(cycles):\n",
    "        new_df = old_df.sample(frac=1).reset_index(drop=True)\n",
    "        return new_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:29.376188400Z",
     "start_time": "2024-08-23T07:26:29.367171800Z"
    }
   },
   "id": "10bb994e77f4286b"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Function to encode the dataset\n",
    "def encode_examples(examples):\n",
    "    encoding = tokenizer(examples['hypothesis'], examples['premise'], truncation=True)\n",
    "    encoding['labels'] = examples['class']\n",
    "    encoding[\"input_sentence\"] = tokenizer.batch_decode(encoding.input_ids)\n",
    "    return encoding"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:29.390156200Z",
     "start_time": "2024-08-23T07:26:29.376188400Z"
    }
   },
   "id": "c1b88512f2f82e66"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=test_size, random_state=42)\n",
    "train_shuffle_df = shuffle_df(train_data)\n",
    "test_shuffle_df = shuffle_df(test_data)\n",
    "\n",
    "# Create a Dataset object from the shuffled train DataFrame\n",
    "train = Dataset.from_pandas(train_shuffle_df)\n",
    "test = Dataset.from_pandas(test_shuffle_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:29.469327700Z",
     "start_time": "2024-08-23T07:26:29.385151600Z"
    }
   },
   "id": "116b8e05c088d0db"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/143 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c4daf58a25e4e8a98c5d8369161de95"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# Map the create_input_sequence function to the train and test datasets - This function encodes the data, adds labels, and generates input sentences\n",
    "train_dataset = train.map(encode_examples, batched=True, batch_size=1, remove_columns=[\"class\", \"premise\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:29.607540700Z",
     "start_time": "2024-08-23T07:26:29.422712700Z"
    }
   },
   "id": "bfcc70bafd3c84bd"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/575 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "853579b06fd74a89b5d6354b6a264a86"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = test.map(encode_examples, batched=True, batch_size=1, remove_columns=[\"class\", \"premise\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:30.230308200Z",
     "start_time": "2024-08-23T07:26:29.607540700Z"
    }
   },
   "id": "1c7972a0d58b6ecd"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from transformers import EvalPrediction\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    # Extracting predictions from EvalPrediction object\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    # Obtaining the predicted classes\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "\n",
    "    # Calculating the ratio of predictions equals to 2 (assumed label)\n",
    "    ratio = np.mean(preds == 2)\n",
    "\n",
    "    # Dictionary to store computed metrics\n",
    "    metric_result = {}\n",
    "\n",
    "    # Loading evaluation metrics\n",
    "    metric_f1 = load_metric(\"f1\", trust_remote_code=True)\n",
    "    metric_precision = load_metric(\"precision\", trust_remote_code=True)\n",
    "    metric_recall = load_metric(\"recall\", trust_remote_code=True)\n",
    "    metric_acc = load_metric(\"accuracy\", trust_remote_code=True)\n",
    "\n",
    "    # Computing various metrics\n",
    "    metric_result[\"accuracy\"] = metric_acc.compute(predictions=preds, references=p.label_ids)[\"accuracy\"]\n",
    "    metric_result[\"precision\"] = metric_precision.compute(predictions=preds, references=p.label_ids, average='macro')['precision']\n",
    "    metric_result[\"recall\"] = metric_recall.compute(predictions=preds, references=p.label_ids, average='macro')[\"recall\"]\n",
    "    metric_result[\"f1\"] = metric_f1.compute(predictions=preds, references=p.label_ids, average='macro')[\"f1\"]\n",
    "    metric_result[\"ratio\"] = ratio\n",
    "\n",
    "    return metric_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:30.236027700Z",
     "start_time": "2024-08-23T07:26:30.233003600Z"
    }
   },
   "id": "3c93a6f310cad0fe"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Freeze all base parameters of transformer \n",
    "if freeze:\n",
    "    for param in model.base_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # check which paramteres are trained\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"Parameter {name}: {'trainierbar' if param.requires_grad else 'eingefroren'}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:30.262772600Z",
     "start_time": "2024-08-23T07:26:30.237239600Z"
    }
   },
   "id": "1987a16befc2eb6d"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "#model.gradient_checkpointing_enable()\n",
    "#model.config.use_cache = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:30.273422300Z",
     "start_time": "2024-08-23T07:26:30.253263300Z"
    }
   },
   "id": "d73f1874d8dc8035"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"FinalRuns\",\n",
    "    num_train_epochs=eps,              # total number of training epochs\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=train_batch,   # batch size per device during training\n",
    "    per_device_eval_batch_size=eval_batch,    # batch size for evaluation\n",
    "    warmup_ratio=warm_ratio,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=wd,               # strength of weight decay\n",
    "    fp16=True                        # mixed precision training\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:30.324789Z",
     "start_time": "2024-08-23T07:26:30.268426300Z"
    }
   },
   "id": "aa6edd377e20632b"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:30.626996Z",
     "start_time": "2024-08-23T07:26:30.326129300Z"
    }
   },
   "id": "868904be129ec2a8"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m To get all data logged automatically, import comet_ml before the following modules: torch, sklearn.\n",
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Experiment is live on comet.com https://www.comet.com/sailerco/huggingface/7785f721530740cebf4104fe9b7dccdb\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 2/30 : < :, Epoch 0.20/6]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m ---------------------------------------------------------------------------------------\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Comet.ml Experiment Summary\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m ---------------------------------------------------------------------------------------\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Data:\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     display_summary_level : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     name                  : magic_taper_8576\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     url                   : https://www.comet.com/sailerco/huggingface/7785f721530740cebf4104fe9b7dccdb\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Metrics:\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     epoch                          : 6.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     total_flos                     : 29670681090960.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train/epoch                    : 6.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train/total_flos               : 29670681090960.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train/train_loss               : 0.6096959431966146\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train/train_runtime            : 7.0672\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train/train_samples_per_second : 121.407\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train/train_steps_per_second   : 4.245\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train_loss                     : 0.6096959431966146\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train_runtime                  : 7.0672\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train_samples_per_second       : 121.407\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train_steps_per_second         : 4.245\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Parameters:\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/_n_gpu                                  : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/_no_sync_in_gradient_accumulation       : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/_setup_devices                          : cuda:0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/accelerator_config                      : AcceleratorConfig(split_batches=False, dispatch_batches=None, even_batches=True, use_seedable_sampler=True, non_blocking=False, gradient_accumulation_kwargs=None)\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/adafactor                               : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/adam_beta1                              : 0.9\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/adam_beta2                              : 0.999\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/adam_epsilon                            : 1e-08\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/auto_find_batch_size                    : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/batch_eval_metrics                      : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/bf16                                    : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/bf16_full_eval                          : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/data_seed                               : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/dataloader_drop_last                    : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/dataloader_num_workers                  : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/dataloader_persistent_workers           : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/dataloader_pin_memory                   : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/dataloader_prefetch_factor              : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/ddp_backend                             : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/ddp_broadcast_buffers                   : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/ddp_bucket_cap_mb                       : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/ddp_find_unused_parameters              : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/ddp_timeout                             : 1800\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/ddp_timeout_delta                       : 0:30:00\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/debug                                   : []\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/deepspeed                               : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/deepspeed_plugin                        : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/default_optim                           : adamw_torch\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/device                                  : cuda:0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/disable_tqdm                            : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/dispatch_batches                        : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/distributed_state                       : Distributed environment: DistributedType.NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/do_eval                                 : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/do_predict                              : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/do_train                                : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/eval_accumulation_steps                 : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/eval_batch_size                         : 32\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/eval_delay                              : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/eval_do_concat_batches                  : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/eval_steps                              : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/eval_strategy                           : IntervalStrategy.NO\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/evaluation_strategy                     : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/fp16                                    : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/fp16_backend                            : auto\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/fp16_full_eval                          : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/fp16_opt_level                          : O1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/framework                               : pt\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/fsdp                                    : []\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/fsdp_config                             : {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/fsdp_min_num_params                     : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/fsdp_transformer_layer_cls_to_wrap      : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/full_determinism                        : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/gradient_accumulation_steps             : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/gradient_checkpointing                  : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/gradient_checkpointing_kwargs           : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/greater_is_better                       : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/group_by_length                         : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/half_precision_backend                  : auto\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/hub_always_push                         : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/hub_model_id                            : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/hub_private_repo                        : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/hub_strategy                            : HubStrategy.EVERY_SAVE\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/hub_token                               : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/ignore_data_skip                        : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/include_inputs_for_metrics              : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/include_num_input_tokens_seen           : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/include_tokens_per_second               : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/jit_mode_eval                           : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/label_names                             : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/label_smoothing_factor                  : 0.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/learning_rate                           : 2e-05\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/length_column_name                      : length\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/load_best_model_at_end                  : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/local_process_index                     : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/local_rank                              : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/log_level                               : passive\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/log_level_replica                       : warning\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/log_on_each_node                        : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/logging_dir                             : FinalRuns\\runs\\Aug23_09-26-30_DESKTOP-968BNEJ\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/logging_first_step                      : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/logging_nan_inf_filter                  : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/logging_steps                           : 500\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/logging_strategy                        : IntervalStrategy.STEPS\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/lr_scheduler_kwargs                     : {}\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/lr_scheduler_type                       : SchedulerType.LINEAR\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/max_grad_norm                           : 1.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/max_steps                               : -1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/metric_for_best_model                   : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/mp_parameters                           : \n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/n_gpu                                   : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/neftune_noise_alpha                     : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/no_cuda                                 : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/num_train_epochs                        : 6\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/optim                                   : OptimizerNames.ADAMW_TORCH\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/optim_args                              : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/optim_target_modules                    : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/output_dir                              : FinalRuns\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/overwrite_output_dir                    : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/parallel_mode                           : ParallelMode.NOT_PARALLEL\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/past_index                              : -1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/per_device_eval_batch_size              : 32\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/per_device_train_batch_size             : 32\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/per_gpu_eval_batch_size                 : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/per_gpu_train_batch_size                : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/place_model_on_device                   : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/prediction_loss_only                    : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/process_index                           : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/push_to_hub                             : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/push_to_hub_model_id                    : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/push_to_hub_organization                : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/push_to_hub_token                       : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/ray_scope                               : last\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/remove_unused_columns                   : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/report_to                               : ['comet_ml', 'tensorboard']\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/restore_callback_states_from_checkpoint : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/resume_from_checkpoint                  : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/run_name                                : FinalRuns\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/save_on_each_node                       : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/save_only_model                         : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/save_safetensors                        : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/save_steps                              : 500\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/save_strategy                           : IntervalStrategy.STEPS\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/save_total_limit                        : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/seed                                    : 42\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/should_log                              : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/should_save                             : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/skip_memory_metrics                     : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/split_batches                           : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/tf32                                    : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/torch_compile                           : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/torch_compile_backend                   : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/torch_compile_mode                      : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/torchdynamo                             : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/tpu_metrics_debug                       : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/tpu_num_cores                           : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/train_batch_size                        : 32\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/use_cpu                                 : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/use_ipex                                : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/use_legacy_prediction_loop              : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/use_mps_device                          : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/warmup_ratio                            : 0.1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/warmup_steps                            : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/weight_decay                            : 0.06\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/world_size                              : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/_attn_implementation                  : eager\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/_attn_implementation_internal         : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/_auto_class                           : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/_commit_hash                          : 6f5cf0a2b59cabb106aca4c287eed12e357e90eb\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/_name_or_path                         : MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/add_cross_attention                   : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/architectures                         : ['DebertaV2ForSequenceClassification']\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/attention_probs_dropout_prob          : 0.1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/attribute_map                         : {}\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/bad_words_ids                         : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/begin_suppress_tokens                 : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/bos_token_id                          : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/chunk_size_feed_forward               : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/cross_attention_hidden_size           : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/decoder_start_token_id                : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/diversity_penalty                     : 0.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/do_sample                             : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/early_stopping                        : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/encoder_no_repeat_ngram_size          : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/eos_token_id                          : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/exponential_decay_length_penalty      : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/finetuning_task                       : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/forced_bos_token_id                   : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/forced_eos_token_id                   : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/hidden_act                            : gelu\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/hidden_dropout_prob                   : 0.1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/hidden_size                           : 768\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/id2label                              : {0: 'entailment', 1: 'neutral', 2: 'contradiction'}\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/initializer_range                     : 0.02\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/intermediate_size                     : 3072\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/is_composition                        : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/is_decoder                            : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/is_encoder_decoder                    : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/label2id                              : {'contradiction': 2, 'entailment': 0, 'neutral': 1}\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/layer_norm_eps                        : 1e-07\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/length_penalty                        : 1.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/max_length                            : 20\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/max_position_embeddings               : 512\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/max_relative_positions                : -1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/min_length                            : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/model_type                            : deberta-v2\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/name_or_path                          : MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/no_repeat_ngram_size                  : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/norm_rel_ebd                          : layer_norm\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/num_attention_heads                   : 12\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/num_beam_groups                       : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/num_beams                             : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/num_hidden_layers                     : 12\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/num_labels                            : 3\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/num_return_sequences                  : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/output_attentions                     : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/output_hidden_states                  : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/output_scores                         : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/pad_token_id                          : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/pooler_dropout                        : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/pooler_hidden_act                     : gelu\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/pooler_hidden_size                    : 768\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/pos_att_type                          : ['p2c', 'c2p']\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/position_biased_input                 : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/position_buckets                      : 256\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/prefix                                : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/problem_type                          : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/pruned_heads                          : {}\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/relative_attention                    : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/remove_invalid_values                 : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/repetition_penalty                    : 1.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/return_dict                           : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/return_dict_in_generate               : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/sep_token_id                          : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/share_att_key                         : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/suppress_tokens                       : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/task_specific_params                  : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/temperature                           : 1.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/tf_legacy_loss                        : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/tie_encoder_decoder                   : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/tie_word_embeddings                   : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/tokenizer_class                       : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/top_k                                 : 50\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/top_p                                 : 1.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/torch_dtype                           : torch.float16\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/torchscript                           : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/transformers_version                  : 4.11.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/type_vocab_size                       : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/typical_p                             : 1.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/use_bfloat16                          : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/use_return_dict                       : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/vocab_size                            : 128001\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Uploads:\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     environment details      : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     filename                 : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     git metadata             : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     git-patch (uncompressed) : 1 (5.43 MB)\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     installed packages       : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     model graph              : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     notebook                 : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     source_code              : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m \n",
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m To get all data logged automatically, import comet_ml before the following modules: torch, sklearn.\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Still uploading 1 file(s), remaining 410.52 KB/1.99 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=30, training_loss=0.6096959431966146, metrics={'train_runtime': 7.0672, 'train_samples_per_second': 121.407, 'train_steps_per_second': 4.245, 'total_flos': 29670681090960.0, 'train_loss': 0.6096959431966146, 'epoch': 6.0})"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:41.706529500Z",
     "start_time": "2024-08-23T07:26:30.627997100Z"
    }
   },
   "id": "f0ce14d92ab4883a"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "184348419"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.get_num_trainable_parameters() #6 Epochen: 1052675 vs. 407344131"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:41.712654900Z",
     "start_time": "2024-08-23T07:26:41.706529500Z"
    }
   },
   "id": "ada1a50f70ade173"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/18 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Coco\\AppData\\Local\\Temp\\ipykernel_13348\\1435740654.py:16: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric_f1 = load_metric(\"f1\", trust_remote_code=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'eval_loss': 0.35329923033714294,\n 'eval_accuracy': 0.8782608695652174,\n 'eval_precision': 0.8877965430142143,\n 'eval_recall': 0.8789473684210527,\n 'eval_f1': 0.8776387470207695,\n 'eval_ratio': 0.5756521739130435,\n 'eval_runtime': 3.2431,\n 'eval_samples_per_second': 177.298,\n 'eval_steps_per_second': 5.55,\n 'epoch': 6.0}"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:44.968830700Z",
     "start_time": "2024-08-23T07:26:41.709656600Z"
    }
   },
   "id": "e090799b0380d48b"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "DebertaV2ForSequenceClassification(\n  (deberta): DebertaV2Model(\n    (embeddings): DebertaV2Embeddings(\n      (word_embeddings): Embedding(128001, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n      (dropout): StableDropout()\n    )\n    (encoder): DebertaV2Encoder(\n      (layer): ModuleList(\n        (0-11): 12 x DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n      )\n      (rel_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): StableDropout()\n  )\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n  (dropout): StableDropout()\n)"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:44.975472Z",
     "start_time": "2024-08-23T07:26:44.969843300Z"
    }
   },
   "id": "3490ff0933eeb0a1"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "trainer.save_model(f\"FinalRuns_PreTrained/{model_config_name}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:46.500683Z",
     "start_time": "2024-08-23T07:26:44.973966400Z"
    }
   },
   "id": "f5c6670134492f59"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "#model.save_pretrained(f\"test_trainer_Trainer_{model_name}/{datetime.now().strftime('%Y%m%d-%H%M%S')}\",from_pt=True)\n",
    "model.save_pretrained(f\"FinalRuns_PreTrained_{model_name}/{model_config_name}\",from_pt=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:51.060228700Z",
     "start_time": "2024-08-23T07:26:46.501682700Z"
    }
   },
   "id": "ee79980b6b0b609e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create Pipeline with the new model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c08dac08f8aae47"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# Create new pipeline object with our fine-tuned model and tokenizer\n",
    "model.config.use_cache = True\n",
    "classifier_after = pipeline('zero-shot-classification', model=model, tokenizer=tokenizer, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:26:51.065957100Z",
     "start_time": "2024-08-23T07:26:51.061229900Z"
    }
   },
   "id": "1b36bf38181d6364"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "hypothesis_template = \"To resolve this issue the skill {} is needed.\"\n",
    "if hypothesis_template_available:\n",
    "    after_results = classifier_after(user_stories, labels, multi_label=True, hypothesis_template=hypothesis_template)\n",
    "else:\n",
    "    after_results = classifier_after(user_stories, labels, multi_label=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:30:35.366337100Z",
     "start_time": "2024-08-23T07:26:51.063897600Z"
    }
   },
   "id": "a29189341f44795f"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "with open(f\"output_txt/{model_config_name}.txt\", 'w') as f:\n",
    "    for story, result in zip(user_stories, after_results):\n",
    "        f.write(f\"Story: {story}\\n\")\n",
    "        for label, score in zip(result['labels'], result['scores']):\n",
    "            f.write(f\"- {label}: {score:.2f}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:30:35.381014600Z",
     "start_time": "2024-08-23T07:30:35.369337Z"
    }
   },
   "id": "e937c71119f19bbe"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Thesis\\FineTuning\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "file_dir = os.getcwd()\n",
    "csv = Conv.CsvConverter(os.path.join(file_dir, 'output_txt',f'{model_config_name}.txt'),\n",
    "                        os.path.join(file_dir, 'output_csv', f'{model_config_name}.csv'),\n",
    "                        'Story')\n",
    "csv.convert()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:30:35.418958300Z",
     "start_time": "2024-08-23T07:30:35.382016600Z"
    }
   },
   "id": "13d439cfa2b1a884"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---_1_08_6_2e-05_3232_0.1_0.06---\n",
      "\n",
      "---DEBERTA---\n",
      "  Threshold    Label Density    Subset Accuracy    Recall    F1 Score    F-Beta Score    Hamming Loss    Jaccard Index\n",
      "-----------  ---------------  -----------------  --------  ----------  --------------  --------------  ---------------\n",
      "       1                0.97               0.01    0.1719      0.2251          0.1886          0.0261           0.1603\n",
      "       0.95             3.54               0.17    0.72        0.6796          0.6966          0.017            0.5785\n",
      "       0.9              4.03               0.16    0.7579      0.6813          0.7167          0.0184           0.5716\n",
      "       0.8              4.55               0.12    0.7865      0.6741          0.7281          0.0208           0.5566\n",
      "       0.5              5.42               0.08    0.8069      0.6419          0.7195          0.0265           0.5151\n",
      "Differences:\n",
      "  Threshold    Label Density    Subset Accuracy    Recall    F1 Score    F-Beta Score    Hamming Loss    Jaccard Index\n",
      "-----------  ---------------  -----------------  --------  ----------  --------------  --------------  ---------------\n",
      "          0             0.88               0.01    0.1601      0.2063          0.1748         -0.0019           0.1485\n",
      "          0             0.87               0.05    0.2519      0.1993          0.2288         -0.0066           0.1933\n",
      "          0             0.37              -0.01    0.1036      0.082           0.095          -0.0037           0.0752\n",
      "          0            -0.12               0.02    0.0591      0.0729          0.0679         -0.0048           0.0723\n",
      "          0            -4.86               0.08   -0.0036      0.2044          0.1398         -0.0381           0.2148\n"
     ]
    }
   ],
   "source": [
    "import MetricsGenerator as Metrics\n",
    "dir = os.getcwd()\n",
    "end_dir = os.path.join(dir, \"output_csv\")\n",
    "if model_name == \"bart\":\n",
    "    metrics = Metrics.MetricsGenerator(f\"_{config}\", dir, end_dir, False, True, False).main()\n",
    "else:\n",
    "    metrics = Metrics.MetricsGenerator(f\"_{config}\", dir, end_dir, False, False, True).main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T07:30:35.533785Z",
     "start_time": "2024-08-23T07:30:35.419958400Z"
    }
   },
   "id": "7aa1450656a492eb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

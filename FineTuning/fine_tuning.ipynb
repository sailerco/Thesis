{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset, load_metric\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "import CsvConverter as Conv\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:48.139056900Z",
     "start_time": "2024-08-29T09:15:38.409801100Z"
    }
   },
   "id": "7dee6fb31143df24"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Configure Parameters and Name"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e87cf948e273856"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model_name = \"deberta\"\n",
    "\n",
    "train_batch = 32\n",
    "eval_batch = 32\n",
    "lr = 2e-05\n",
    "eps = 6\n",
    "wd = 0.06\n",
    "warm_ratio = 0.1\n",
    "\n",
    "freeze = False\n",
    "hypothesis_template_available = False\n",
    "\n",
    "test_size = 0.8"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:48.142519600Z",
     "start_time": "2024-08-29T09:15:48.141514100Z"
    }
   },
   "id": "8e34856d8ecdba6a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# generate output name based on configurations\n",
    "if hypothesis_template_available:\n",
    "    config = f\"{str(test_size).replace('.', '')}_HP_{eps}_{lr}_{train_batch}{eval_batch}_{warm_ratio}_{wd}\"\n",
    "elif freeze:\n",
    "    config = f\"{str(test_size).replace('.', '')}_freeze_{eps}_{lr}_{train_batch}{eval_batch}_{warm_ratio}_{wd}\"\n",
    "else:\n",
    "    config = f\"{str(test_size).replace('.', '')}_{eps}_{lr}_{train_batch}{eval_batch}_{warm_ratio}_{wd}\"\n",
    "\n",
    "# Final model configuration name\n",
    "model_config_name = f\"{model_name}_{config}\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:48.157450600Z",
     "start_time": "2024-08-29T09:15:48.143519400Z"
    }
   },
   "id": "56fe0e34913c01ce"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deberta_208_6_2e-05_3232_0.1_0.06\n"
     ]
    }
   ],
   "source": [
    "print(model_config_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:48.163990600Z",
     "start_time": "2024-08-29T09:15:48.157450600Z"
    }
   },
   "id": "e90f1a62e8fa9219"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# select the gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:48.216044900Z",
     "start_time": "2024-08-29T09:15:48.161992100Z"
    }
   },
   "id": "31e9d7966a332671"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extract the entailments and contradictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b66474b9792d2cb2"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# get synthetic user stories and matching skills\n",
    "user_stories_df = pd.read_csv('../Classification_Synth/userStories.csv', delimiter=';')\n",
    "user_stories = user_stories_df['user_stories'].tolist()\n",
    "\n",
    "# cleans up the skills representation in the user stories dataframe\n",
    "user_stories_df['skills'] = user_stories_df['skills'].apply(lambda x: [i.strip().replace(\"'\", \"\") for i in x.split(\",\")])\n",
    "\n",
    "# get skills which were used in the employee database\n",
    "df = pd.read_csv('../DB/datasets/skills.csv', header=None, encoding='ISO-8859-1')\n",
    "labels = df[0].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:48.218415900Z",
     "start_time": "2024-08-29T09:15:48.189444400Z"
    }
   },
   "id": "4fc37699e4844f01"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         user_stories  \\\n0   As a software developer at our company, I want...   \n1   As a software developer at our company, I want...   \n2   As a DevOps engineer at our company, I want to...   \n3   As a software engineer at our cryptocurrency d...   \n4   As a UI/UX designer and developer at our softw...   \n..                                                ...   \n95  As a DevOps engineer, I want to automate the b...   \n96  As a web developer, I want to implement a user...   \n97  As a QA engineer, I want to integrate Selenium...   \n98  As an IT administrator, I want to implement se...   \n99  As a database developer, I want to optimize ou...   \n\n                                               skills  \n0   [MQTT, IoT,  Sensor Integration,  Smart contra...  \n1   [Pandas, scikit-learn, Natural Language Proces...  \n2                                        [GCP, Azure]  \n3   [Cryptocurrency development, IoT, MQTT, Sensor...  \n4        [UI Design, Responsive Design, React Native]  \n..                                                ...  \n95                [GCP, Build Automation, Kubernetes]  \n96   [HTML, React, CSS, UI Design, Web Accessibility]  \n97                    [Agile Methodologies, Selenium]  \n98  [Troubleshooting, Active Directory, Security B...  \n99          [Microsoft SQL Server, RDBMS, MySQL, SQL]  \n\n[100 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_stories</th>\n      <th>skills</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>As a software developer at our company, I want...</td>\n      <td>[MQTT, IoT,  Sensor Integration,  Smart contra...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>As a software developer at our company, I want...</td>\n      <td>[Pandas, scikit-learn, Natural Language Proces...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>As a DevOps engineer at our company, I want to...</td>\n      <td>[GCP, Azure]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>As a software engineer at our cryptocurrency d...</td>\n      <td>[Cryptocurrency development, IoT, MQTT, Sensor...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>As a UI/UX designer and developer at our softw...</td>\n      <td>[UI Design, Responsive Design, React Native]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>As a DevOps engineer, I want to automate the b...</td>\n      <td>[GCP, Build Automation, Kubernetes]</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>As a web developer, I want to implement a user...</td>\n      <td>[HTML, React, CSS, UI Design, Web Accessibility]</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>As a QA engineer, I want to integrate Selenium...</td>\n      <td>[Agile Methodologies, Selenium]</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>As an IT administrator, I want to implement se...</td>\n      <td>[Troubleshooting, Active Directory, Security B...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>As a database developer, I want to optimize ou...</td>\n      <td>[Microsoft SQL Server, RDBMS, MySQL, SQL]</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_stories_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:48.219415900Z",
     "start_time": "2024-08-29T09:15:48.198611300Z"
    }
   },
   "id": "147b8e2ce09340e5"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# load the ground truth, which is later used to extract the contradictions\n",
    "contras_df = pd.read_csv('truth.csv', index_col=0)\n",
    "\n",
    "# Extract NaN skills for each column\n",
    "skills_nan = {col: contras_df.loc[contras_df[col].isna()].index.tolist() for col in contras_df.columns}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:48.227374800Z",
     "start_time": "2024-08-29T09:15:48.209047Z"
    }
   },
   "id": "47016e54ed1b77bf"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Create a new DataFrame with the desired structure\n",
    "new_data = []\n",
    "for col, nan_indices in skills_nan.items():\n",
    "    new_data.append([col, nan_indices])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:48.227374800Z",
     "start_time": "2024-08-29T09:15:48.223637800Z"
    }
   },
   "id": "123fe4e365a4bf62"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "contras_df = pd.DataFrame(new_data, columns=['user_stories', 'skills'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:48.228379200Z",
     "start_time": "2024-08-29T09:15:48.225651600Z"
    }
   },
   "id": "62791ad44eb80544"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Prepeare the base models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb5aa06b87c948b1"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# select the model path based on the configurated model name\n",
    "if model_name == \"bart\":\n",
    "    model_dir = \"facebook/bart-large-mnli\"\n",
    "else:\n",
    "    model_dir = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:49.530073800Z",
     "start_time": "2024-08-29T09:15:48.229380400Z"
    }
   },
   "id": "829d7815be178259"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def get_new_tokens(sentences, vocabulary):\n",
    "    \"\"\"Identifies new tokens from sentences that are not present in the current tokenizer vocabulary.\"\"\"\n",
    "    vocab_set = set(vocabulary)\n",
    "    cleaned_words = (re.sub(r\"[.'\\s\\n]+|('\\s)\", \"\", word).lower().strip() for sentence in sentences for word in sentence)\n",
    "    return [word for word in cleaned_words if word not in vocab_set and word]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:49.536410300Z",
     "start_time": "2024-08-29T09:15:49.531076500Z"
    }
   },
   "id": "ae88222f21275599"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def word_count(word_list):\n",
    "    \"\"\"Counts the frequency of words in a list.\"\"\"\n",
    "    return Counter(word_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:49.537433200Z",
     "start_time": "2024-08-29T09:15:49.534391500Z"
    }
   },
   "id": "3bea5a1bd6ef6217"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def tokenize(data):\n",
    "    \"\"\"Tokenizes the data by adding new tokens to the tokenizer if they appear more than 10 times and have more than 2 characters.\n",
    "     Resizes the model's token embedding size to match the updated tokenizer.\"\"\"\n",
    "    data['premise'] = data['premise'].astype(\"str\")\n",
    "    hypothesis = []\n",
    "    for x in data['hypothesis'].to_list():\n",
    "        hypothesis.extend([item.strip() for item in x])\n",
    "    sentences = data['premise'].to_list() + hypothesis\n",
    "    \n",
    "    vocabulary = tokenizer.get_vocab().keys()\n",
    "    tokens_to_add = get_new_tokens(sentences, vocabulary)\n",
    "    words = word_count(tokens_to_add)\n",
    "    # Initialize an empty list to store new tokens + Loop through the words and their counts\n",
    "    new_tokens = []\n",
    "    for key, value in words.items():\n",
    "        if value > 10 and len(key) > 2:\n",
    "            new_tokens.append(key)\n",
    "    tokenizer.add_tokens(new_tokens)\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:49.550521400Z",
     "start_time": "2024-08-29T09:15:49.539416800Z"
    }
   },
   "id": "4ffe5330af08ecbd"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def synth_to_nli(data, value):\n",
    "    \"\"\" Converts the dataset format to fit the NLI format with 'hypothesis' and 'premise'.\n",
    "     Calls the tokenize function on the dataset.\"\"\"\n",
    "    data = data.copy()\n",
    "    data.rename(columns={'user_stories': 'premise', 'skills': 'hypothesis'}, inplace=True)\n",
    "    data['class'] = value\n",
    "    tokenize(data)\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:49.551520300Z",
     "start_time": "2024-08-29T09:15:49.543035400Z"
    }
   },
   "id": "13d41af88c8a6657"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# based on the model the scores for the entailment and contradiction\n",
    "if model_name == \"bart\":\n",
    "    df = synth_to_nli(user_stories_df, 2) # entailment\n",
    "    contras_df = synth_to_nli(contras_df, 0) # contradiction\n",
    "else:\n",
    "    df = synth_to_nli(user_stories_df, 0) # entailment\n",
    "    contras_df = synth_to_nli(contras_df, 2) # contradiction"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:50.471597800Z",
     "start_time": "2024-08-29T09:15:49.545998Z"
    }
   },
   "id": "631a30f0d15e8848"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# split up the hypothesis labels, and select random contradictions (equals entailment count)\n",
    "df = df.explode('hypothesis')\n",
    "contras_df = contras_df.explode('hypothesis')\n",
    "contras_df = contras_df.sample(359)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:50.480249900Z",
     "start_time": "2024-08-29T09:15:50.472598800Z"
    }
   },
   "id": "fdc718fc1c492d26"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "df = pd.concat([df, contras_df], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:50.485811700Z",
     "start_time": "2024-08-29T09:15:50.483251500Z"
    }
   },
   "id": "1f73f25a60d4b6f5"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:50.492021500Z",
     "start_time": "2024-08-29T09:15:50.485811700Z"
    }
   },
   "id": "c39667717441209e"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              premise1  \\\n0    As a software developer at our company, I want...   \n1    As a software developer at our company, I want...   \n2    As a software developer at our company, I want...   \n3    As a software developer at our company, I want...   \n4    As a software developer at our company, I want...   \n..                                                 ...   \n713  As an IT Project Manager overseeing the develo...   \n714  As an IT Project Manager overseeing the develo...   \n715  As a systems administrator at our software com...   \n716  As a quality assurance engineer, I want to str...   \n717  As a project manager, I want to incorporate ri...   \n\n                       hypothesis1  class  \n0                             MQTT      0  \n1                              IoT      0  \n2               Sensor Integration      0  \n3                  Smart contracts      0  \n4                           Pandas      0  \n..                             ...    ...  \n713                          NoSQL      2  \n714                           MQTT      2  \n715  Hardware/Software Integration      2  \n716                  Data Modeling      2  \n717          Responsive Web Design      2  \n\n[718 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>premise1</th>\n      <th>hypothesis1</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>As a software developer at our company, I want...</td>\n      <td>MQTT</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>As a software developer at our company, I want...</td>\n      <td>IoT</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>As a software developer at our company, I want...</td>\n      <td>Sensor Integration</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>As a software developer at our company, I want...</td>\n      <td>Smart contracts</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>As a software developer at our company, I want...</td>\n      <td>Pandas</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>713</th>\n      <td>As an IT Project Manager overseeing the develo...</td>\n      <td>NoSQL</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>714</th>\n      <td>As an IT Project Manager overseeing the develo...</td>\n      <td>MQTT</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>715</th>\n      <td>As a systems administrator at our software com...</td>\n      <td>Hardware/Software Integration</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>716</th>\n      <td>As a quality assurance engineer, I want to str...</td>\n      <td>Data Modeling</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>717</th>\n      <td>As a project manager, I want to incorporate ri...</td>\n      <td>Responsive Web Design</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>718 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:50.517612100Z",
     "start_time": "2024-08-29T09:15:50.490023400Z"
    }
   },
   "id": "3deb5885841e51ff"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def shuffle_df(old_df: pd.DataFrame, cycles: int = 1) -> pd.DataFrame:\n",
    "    np.random.seed(42)\n",
    "    for i in range(cycles):\n",
    "        new_df = old_df.sample(frac=1).reset_index(drop=True)\n",
    "        return new_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:50.518611900Z",
     "start_time": "2024-08-29T09:15:50.497795500Z"
    }
   },
   "id": "1b6d7530dd09d53a"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def encode_examples(examples):\n",
    "    \"\"\"\n",
    "    Encodes examples for NLI training by tokenizing the 'hypothesis' and 'premise' columns.\n",
    "    :returns \n",
    "        A dictionary with tokenized input data and labels.\n",
    "    \"\"\"\n",
    "    encoding = tokenizer(examples['premise'], examples['hypothesis'], truncation=True)\n",
    "    encoding['labels'] = examples['class']\n",
    "    encoding[\"input_sentence\"] = tokenizer.batch_decode(encoding.input_ids)\n",
    "    return encoding"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:50.518611900Z",
     "start_time": "2024-08-29T09:15:50.500305100Z"
    }
   },
   "id": "e7c25ad0c5edbb8"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# selects a random data for the training\n",
    "train_data, test_data = train_test_split(df, test_size=test_size, random_state=42)\n",
    "train_shuffle_df = shuffle_df(train_data)\n",
    "test_shuffle_df = shuffle_df(test_data)\n",
    "\n",
    "# Create a Dataset object from the shuffled train DataFrame\n",
    "train = Dataset.from_pandas(train_shuffle_df)\n",
    "test = Dataset.from_pandas(test_shuffle_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:50.541706300Z",
     "start_time": "2024-08-29T09:15:50.502874600Z"
    }
   },
   "id": "46a9138e2876ca02"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/143 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d4a51e2df3a4c248cb792d3a73193dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# Map the encode_examples function to the train and test datasets - This function encodes the data, adds labels, and generates input sentences\n",
    "train_dataset = train.map(encode_examples, batched=True, batch_size=1, remove_columns=[\"class\", \"hypothesis\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:50.729348800Z",
     "start_time": "2024-08-29T09:15:50.521684400Z"
    }
   },
   "id": "c7b5d628cf4e769a"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/575 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9996cc3a25594e1d96ce8e2a59eee397"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = test.map(encode_examples, batched=True, batch_size=1, remove_columns=[\"class\", \"hypothesis\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:51.364615400Z",
     "start_time": "2024-08-29T09:15:50.730349500Z"
    }
   },
   "id": "317f65ba601b31ac"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from transformers import EvalPrediction\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    # Extracting predictions from EvalPrediction object\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    # Obtaining the predicted classes\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "\n",
    "    # Calculating the ratio of predictions equals to 2 (assumed label)\n",
    "    ratio = np.mean(preds == 2)\n",
    "\n",
    "    # Dictionary to store computed metrics\n",
    "    metric_result = {}\n",
    "\n",
    "    # Loading evaluation metrics\n",
    "    metric_f1 = load_metric(\"f1\", trust_remote_code=True)\n",
    "    metric_precision = load_metric(\"precision\", trust_remote_code=True)\n",
    "    metric_recall = load_metric(\"recall\", trust_remote_code=True)\n",
    "    metric_acc = load_metric(\"accuracy\", trust_remote_code=True)\n",
    "\n",
    "    # Computing various metrics\n",
    "    metric_result[\"accuracy\"] = metric_acc.compute(predictions=preds, references=p.label_ids)[\"accuracy\"]\n",
    "    metric_result[\"precision\"] = metric_precision.compute(predictions=preds, references=p.label_ids, average='macro')['precision']\n",
    "    metric_result[\"recall\"] = metric_recall.compute(predictions=preds, references=p.label_ids, average='macro')[\"recall\"]\n",
    "    metric_result[\"f1\"] = metric_f1.compute(predictions=preds, references=p.label_ids, average='macro')[\"f1\"]\n",
    "    metric_result[\"ratio\"] = ratio\n",
    "\n",
    "    return metric_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:51.374739900Z",
     "start_time": "2024-08-29T09:15:51.366522200Z"
    }
   },
   "id": "3c93a6f310cad0fe"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Freeze all base parameters of transformer \n",
    "if freeze:\n",
    "    for param in model.base_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # check which paramteres are trained\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"Parameter {name}: {'trainierbar' if param.requires_grad else 'eingefroren'}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:51.381794800Z",
     "start_time": "2024-08-29T09:15:51.368530100Z"
    }
   },
   "id": "1987a16befc2eb6d"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "#model.gradient_checkpointing_enable()\n",
    "#model.config.use_cache = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:51.388150400Z",
     "start_time": "2024-08-29T09:15:51.383180400Z"
    }
   },
   "id": "d73f1874d8dc8035"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fine-Tuning the models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ced2512304627c2d"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"FinalRuns\",\n",
    "    num_train_epochs=eps,              # total number of training epochs\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=train_batch,   # batch size per device during training\n",
    "    per_device_eval_batch_size=eval_batch,    # batch size for evaluation\n",
    "    warmup_ratio=warm_ratio,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=wd,               # strength of weight decay\n",
    "    fp16=True                        # mixed precision training\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:51.444251800Z",
     "start_time": "2024-08-29T09:15:51.385695200Z"
    }
   },
   "id": "aa6edd377e20632b"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:15:51.717560400Z",
     "start_time": "2024-08-29T09:15:51.444251800Z"
    }
   },
   "id": "868904be129ec2a8"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m To get all data logged automatically, import comet_ml before the following modules: sklearn, torch.\n",
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Experiment is live on comet.com https://www.comet.com/sailerco/huggingface/66a13a42322c4e96a5a1d82401dbaac3\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 2/30 : < :, Epoch 0.20/6]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m The process of logging environment details (conda environment, git patch) is underway. Please be patient as this may take some time.\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m ---------------------------------------------------------------------------------------\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Comet.ml Experiment Summary\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m ---------------------------------------------------------------------------------------\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Data:\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     display_summary_level : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     name                  : nursing_radius_9397\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     url                   : https://www.comet.com/sailerco/huggingface/66a13a42322c4e96a5a1d82401dbaac3\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Metrics:\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     epoch                          : 6.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     total_flos                     : 30093109036380.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train/epoch                    : 6.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train/total_flos               : 30093109036380.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train/train_loss               : 0.5531073888142903\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train/train_runtime            : 6.3812\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train/train_samples_per_second : 134.458\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train/train_steps_per_second   : 4.701\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train_loss                     : 0.5531073888142903\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train_runtime                  : 6.3812\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train_samples_per_second       : 134.458\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train_steps_per_second         : 4.701\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Parameters:\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/_n_gpu                                  : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/_no_sync_in_gradient_accumulation       : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/_setup_devices                          : cuda:0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/accelerator_config                      : AcceleratorConfig(split_batches=False, dispatch_batches=None, even_batches=True, use_seedable_sampler=True, non_blocking=False, gradient_accumulation_kwargs=None)\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/adafactor                               : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/adam_beta1                              : 0.9\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/adam_beta2                              : 0.999\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/adam_epsilon                            : 1e-08\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/auto_find_batch_size                    : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/batch_eval_metrics                      : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/bf16                                    : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/bf16_full_eval                          : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/data_seed                               : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/dataloader_drop_last                    : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/dataloader_num_workers                  : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/dataloader_persistent_workers           : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/dataloader_pin_memory                   : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/dataloader_prefetch_factor              : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/ddp_backend                             : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/ddp_broadcast_buffers                   : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/ddp_bucket_cap_mb                       : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/ddp_find_unused_parameters              : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/ddp_timeout                             : 1800\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/ddp_timeout_delta                       : 0:30:00\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/debug                                   : []\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/deepspeed                               : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/deepspeed_plugin                        : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/default_optim                           : adamw_torch\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/device                                  : cuda:0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/disable_tqdm                            : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/dispatch_batches                        : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/distributed_state                       : Distributed environment: DistributedType.NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/do_eval                                 : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/do_predict                              : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/do_train                                : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/eval_accumulation_steps                 : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/eval_batch_size                         : 32\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/eval_delay                              : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/eval_do_concat_batches                  : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/eval_steps                              : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/eval_strategy                           : IntervalStrategy.NO\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/evaluation_strategy                     : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/fp16                                    : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/fp16_backend                            : auto\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/fp16_full_eval                          : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/fp16_opt_level                          : O1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/framework                               : pt\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/fsdp                                    : []\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/fsdp_config                             : {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/fsdp_min_num_params                     : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/fsdp_transformer_layer_cls_to_wrap      : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/full_determinism                        : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/gradient_accumulation_steps             : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/gradient_checkpointing                  : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/gradient_checkpointing_kwargs           : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/greater_is_better                       : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/group_by_length                         : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/half_precision_backend                  : auto\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/hub_always_push                         : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/hub_model_id                            : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/hub_private_repo                        : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/hub_strategy                            : HubStrategy.EVERY_SAVE\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/hub_token                               : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/ignore_data_skip                        : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/include_inputs_for_metrics              : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/include_num_input_tokens_seen           : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/include_tokens_per_second               : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/jit_mode_eval                           : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/label_names                             : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/label_smoothing_factor                  : 0.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/learning_rate                           : 2e-05\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/length_column_name                      : length\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/load_best_model_at_end                  : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/local_process_index                     : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/local_rank                              : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/log_level                               : passive\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/log_level_replica                       : warning\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/log_on_each_node                        : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/logging_dir                             : FinalRuns\\runs\\Aug29_11-15-51_DESKTOP-968BNEJ\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/logging_first_step                      : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/logging_nan_inf_filter                  : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/logging_steps                           : 500\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/logging_strategy                        : IntervalStrategy.STEPS\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/lr_scheduler_kwargs                     : {}\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/lr_scheduler_type                       : SchedulerType.LINEAR\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/max_grad_norm                           : 1.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/max_steps                               : -1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/metric_for_best_model                   : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/mp_parameters                           : \n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/n_gpu                                   : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/neftune_noise_alpha                     : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/no_cuda                                 : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/num_train_epochs                        : 6\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/optim                                   : OptimizerNames.ADAMW_TORCH\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/optim_args                              : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/optim_target_modules                    : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/output_dir                              : FinalRuns\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/overwrite_output_dir                    : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/parallel_mode                           : ParallelMode.NOT_PARALLEL\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/past_index                              : -1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/per_device_eval_batch_size              : 32\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/per_device_train_batch_size             : 32\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/per_gpu_eval_batch_size                 : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/per_gpu_train_batch_size                : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/place_model_on_device                   : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/prediction_loss_only                    : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/process_index                           : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/push_to_hub                             : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/push_to_hub_model_id                    : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/push_to_hub_organization                : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/push_to_hub_token                       : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/ray_scope                               : last\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/remove_unused_columns                   : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/report_to                               : ['comet_ml', 'tensorboard']\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/restore_callback_states_from_checkpoint : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/resume_from_checkpoint                  : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/run_name                                : FinalRuns\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/save_on_each_node                       : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/save_only_model                         : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/save_safetensors                        : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/save_steps                              : 500\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/save_strategy                           : IntervalStrategy.STEPS\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/save_total_limit                        : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/seed                                    : 42\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/should_log                              : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/should_save                             : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/skip_memory_metrics                     : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/split_batches                           : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/tf32                                    : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/torch_compile                           : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/torch_compile_backend                   : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/torch_compile_mode                      : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/torchdynamo                             : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/tpu_metrics_debug                       : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/tpu_num_cores                           : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/train_batch_size                        : 32\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/use_cpu                                 : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/use_ipex                                : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/use_legacy_prediction_loop              : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/use_mps_device                          : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/warmup_ratio                            : 0.1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/warmup_steps                            : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/weight_decay                            : 0.06\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args/world_size                              : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/_attn_implementation                  : eager\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/_attn_implementation_internal         : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/_auto_class                           : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/_commit_hash                          : 6f5cf0a2b59cabb106aca4c287eed12e357e90eb\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/_name_or_path                         : MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/add_cross_attention                   : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/architectures                         : ['DebertaV2ForSequenceClassification']\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/attention_probs_dropout_prob          : 0.1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/attribute_map                         : {}\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/bad_words_ids                         : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/begin_suppress_tokens                 : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/bos_token_id                          : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/chunk_size_feed_forward               : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/cross_attention_hidden_size           : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/decoder_start_token_id                : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/diversity_penalty                     : 0.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/do_sample                             : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/early_stopping                        : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/encoder_no_repeat_ngram_size          : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/eos_token_id                          : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/exponential_decay_length_penalty      : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/finetuning_task                       : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/forced_bos_token_id                   : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/forced_eos_token_id                   : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/hidden_act                            : gelu\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/hidden_dropout_prob                   : 0.1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/hidden_size                           : 768\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/id2label                              : {0: 'entailment', 1: 'neutral', 2: 'contradiction'}\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/initializer_range                     : 0.02\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/intermediate_size                     : 3072\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/is_composition                        : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/is_decoder                            : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/is_encoder_decoder                    : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/label2id                              : {'contradiction': 2, 'entailment': 0, 'neutral': 1}\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/layer_norm_eps                        : 1e-07\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/length_penalty                        : 1.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/max_length                            : 20\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/max_position_embeddings               : 512\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/max_relative_positions                : -1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/min_length                            : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/model_type                            : deberta-v2\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/name_or_path                          : MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/no_repeat_ngram_size                  : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/norm_rel_ebd                          : layer_norm\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/num_attention_heads                   : 12\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/num_beam_groups                       : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/num_beams                             : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/num_hidden_layers                     : 12\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/num_labels                            : 3\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/num_return_sequences                  : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/output_attentions                     : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/output_hidden_states                  : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/output_scores                         : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/pad_token_id                          : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/pooler_dropout                        : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/pooler_hidden_act                     : gelu\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/pooler_hidden_size                    : 768\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/pos_att_type                          : ['p2c', 'c2p']\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/position_biased_input                 : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/position_buckets                      : 256\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/prefix                                : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/problem_type                          : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/pruned_heads                          : {}\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/relative_attention                    : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/remove_invalid_values                 : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/repetition_penalty                    : 1.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/return_dict                           : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/return_dict_in_generate               : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/sep_token_id                          : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/share_att_key                         : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/suppress_tokens                       : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/task_specific_params                  : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/temperature                           : 1.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/tf_legacy_loss                        : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/tie_encoder_decoder                   : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/tie_word_embeddings                   : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/tokenizer_class                       : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/top_k                                 : 50\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/top_p                                 : 1.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/torch_dtype                           : torch.float16\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/torchscript                           : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/transformers_version                  : 4.11.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/type_vocab_size                       : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/typical_p                             : 1.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/use_bfloat16                          : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/use_return_dict                       : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config/vocab_size                            : 128001\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Uploads:\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     environment details      : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     filename                 : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     git metadata             : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     git-patch (uncompressed) : 1 (80.13 KB)\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     installed packages       : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     model graph              : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     notebook                 : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     source_code              : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m \n",
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m To get all data logged automatically, import comet_ml before the following modules: sklearn, torch.\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Uploading 266 metrics, params and output messages\n"
     ]
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=30, training_loss=0.5531073888142903, metrics={'train_runtime': 6.3812, 'train_samples_per_second': 134.458, 'train_steps_per_second': 4.701, 'total_flos': 30093109036380.0, 'train_loss': 0.5531073888142903, 'epoch': 6.0})"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:16:13.513982800Z",
     "start_time": "2024-08-29T09:15:51.717560400Z"
    }
   },
   "id": "f0ce14d92ab4883a"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "184348419"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.get_num_trainable_parameters() #6 Epochen: 1052675 vs. 407344131"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:16:13.514489900Z",
     "start_time": "2024-08-29T09:16:13.510736800Z"
    }
   },
   "id": "ada1a50f70ade173"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/18 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Coco\\AppData\\Local\\Temp\\ipykernel_8788\\1435740654.py:16: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric_f1 = load_metric(\"f1\", trust_remote_code=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'eval_loss': 0.3496900200843811,\n 'eval_accuracy': 0.8817391304347826,\n 'eval_precision': 0.8868595709247649,\n 'eval_recall': 0.8822444041137326,\n 'eval_f1': 0.881437547000461,\n 'eval_ratio': 0.5547826086956522,\n 'eval_runtime': 3.2278,\n 'eval_samples_per_second': 178.142,\n 'eval_steps_per_second': 5.577,\n 'epoch': 6.0}"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:16:16.778875Z",
     "start_time": "2024-08-29T09:16:13.514489900Z"
    }
   },
   "id": "e090799b0380d48b"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "DebertaV2ForSequenceClassification(\n  (deberta): DebertaV2Model(\n    (embeddings): DebertaV2Embeddings(\n      (word_embeddings): Embedding(128001, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n      (dropout): StableDropout()\n    )\n    (encoder): DebertaV2Encoder(\n      (layer): ModuleList(\n        (0-11): 12 x DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n      )\n      (rel_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): StableDropout()\n  )\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n  (dropout): StableDropout()\n)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:16:16.783830900Z",
     "start_time": "2024-08-29T09:16:16.778875Z"
    }
   },
   "id": "3490ff0933eeb0a1"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "#other ways to save the model, will only save the config.json and model safetensor\n",
    "#trainer.save_model(f\"FinalRuns_PreTrained/{model_config_name}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:16:16.831141900Z",
     "start_time": "2024-08-29T09:16:16.782831900Z"
    }
   },
   "id": "f5c6670134492f59"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "model.save_pretrained(f\"FinalRuns_PreTrained_{model_name}/{model_config_name}\",from_pt=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:16:18.237496200Z",
     "start_time": "2024-08-29T09:16:16.800617600Z"
    }
   },
   "id": "ee79980b6b0b609e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Zero-Shot Classification with the new model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c08dac08f8aae47"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# Create new pipeline object with our fine-tuned model and tokenizer\n",
    "model.config.use_cache = True\n",
    "classifier_after = pipeline('zero-shot-classification', model=model, tokenizer=tokenizer, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:16:18.243919Z",
     "start_time": "2024-08-29T09:16:18.238496500Z"
    }
   },
   "id": "1b36bf38181d6364"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# zero shot classification\n",
    "hypothesis_template = \"To resolve this issue the skill {} is needed.\"\n",
    "if hypothesis_template_available:\n",
    "    after_results = classifier_after(user_stories, labels, multi_label=True, hypothesis_template=hypothesis_template)\n",
    "else:\n",
    "    after_results = classifier_after(user_stories, labels, multi_label=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:19:53.725040100Z",
     "start_time": "2024-08-29T09:16:18.241908600Z"
    }
   },
   "id": "a29189341f44795f"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# save to text file\n",
    "with open(f\"output_txt/{model_config_name}.txt\", 'w') as f:\n",
    "    for story, result in zip(user_stories, after_results):\n",
    "        f.write(f\"Story: {story}\\n\")\n",
    "        for label, score in zip(result['labels'], result['scores']):\n",
    "            f.write(f\"- {label}: {score:.2f}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:19:53.736146100Z",
     "start_time": "2024-08-29T09:19:53.726040300Z"
    }
   },
   "id": "e937c71119f19bbe"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# convert to csv\n",
    "file_dir = os.getcwd()\n",
    "csv = Conv.CsvConverter(os.path.join(file_dir, 'output_txt',f'{model_config_name}.txt'),\n",
    "                        os.path.join(file_dir, 'output_csv', f'{model_config_name}.csv'),\n",
    "                        'Story')\n",
    "csv.convert()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:19:53.770268800Z",
     "start_time": "2024-08-29T09:19:53.736657800Z"
    }
   },
   "id": "13d439cfa2b1a884"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---_208_6_2e-05_3232_0.1_0.06---\n",
      "\n",
      "---DEBERTA---\n",
      "  Threshold    Label Density    Subset Accuracy    Recall    F1 Score    F-Beta Score    Hamming Loss    Jaccard Index\n",
      "-----------  ---------------  -----------------  --------  ----------  --------------  --------------  ---------------\n",
      "       1                1.1                0.02    0.1897      0.2404          0.2057          0.026            0.1738\n",
      "       0.95             3.87               0.13    0.7397      0.6721          0.7041          0.0186           0.5592\n",
      "       0.9              4.33               0.11    0.768       0.6704          0.7172          0.0203           0.5516\n",
      "       0.8              4.88               0.13    0.7917      0.6573          0.7224          0.0232           0.536\n",
      "       0.5              6.22               0.02    0.8275      0.6057          0.7103          0.0315           0.4655\n",
      "Differences:\n",
      "  Threshold    Label Density    Subset Accuracy    Recall    F1 Score    F-Beta Score    Hamming Loss    Jaccard Index\n",
      "-----------  ---------------  -----------------  --------  ----------  --------------  --------------  ---------------\n",
      "          0             1.01               0.02    0.1779      0.2216          0.1919         -0.002            0.162\n",
      "          0             1.2                0.01    0.2716      0.1918          0.2363         -0.005            0.174\n",
      "          0             0.67              -0.06    0.1137      0.0711          0.0955         -0.0018           0.0552\n",
      "          0             0.21               0.03    0.0643      0.0561          0.0622         -0.0024           0.0517\n",
      "          0            -4.06               0.02    0.017       0.1682          0.1306         -0.0331           0.1652\n"
     ]
    }
   ],
   "source": [
    "# generate metrics\n",
    "import MetricsGenerator as Metrics\n",
    "dir = os.getcwd()\n",
    "end_dir = os.path.join(dir, \"output_csv\")\n",
    "if model_name == \"bart\":\n",
    "    metrics = Metrics.MetricsGenerator(f\"_{config}\", dir, end_dir, False, True, False).main()\n",
    "else:\n",
    "    metrics = Metrics.MetricsGenerator(f\"_{config}\", dir, end_dir, False, False, True).main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T09:19:53.865959700Z",
     "start_time": "2024-08-29T09:19:53.771269900Z"
    }
   },
   "id": "7aa1450656a492eb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

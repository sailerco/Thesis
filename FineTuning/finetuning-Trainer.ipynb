{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset, load_metric\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "import CsvConverter as Conv\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:12.625823400Z",
     "start_time": "2024-07-10T13:47:53.424511200Z"
    }
   },
   "id": "7dee6fb31143df24"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:12.673602500Z",
     "start_time": "2024-07-10T13:48:12.626821500Z"
    }
   },
   "id": "31e9d7966a332671"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "user_stories_df = pd.read_csv('../DB_GroundTruth/userStories.csv', delimiter=';')\n",
    "user_stories = user_stories_df['user_stories'].tolist()\n",
    "df = pd.read_csv('D:/Thesis/DB/datasets/skills.csv', header=None, encoding='ISO-8859-1')\n",
    "labels = df[0].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:12.695237400Z",
     "start_time": "2024-07-10T13:48:12.676602800Z"
    }
   },
   "id": "4fc37699e4844f01"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "user_stories_df['skills'] = user_stories_df['skills'].apply(lambda x: [i.strip().replace(\"'\", \"\") for i in x.split(\",\")])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:12.702832800Z",
     "start_time": "2024-07-10T13:48:12.696237800Z"
    }
   },
   "id": "a5c5def21d5a0f1b"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         user_stories  \\\n0   As a software developer at our company, I want...   \n1   As a software developer at our company, I want...   \n2   As a DevOps engineer at our company, I want to...   \n3   As a software engineer at our cryptocurrency d...   \n4   As a UI/UX designer and developer at our softw...   \n..                                                ...   \n95  As a DevOps engineer, I want to automate the b...   \n96  As a web developer, I want to implement a user...   \n97  As a QA engineer, I want to integrate Selenium...   \n98  As an IT administrator, I want to implement se...   \n99  As a database developer, I want to optimize ou...   \n\n                                               skills  \n0   [MQTT, IoT,  Sensor Integration,  Smart contra...  \n1   [Pandas, scikit-learn, Natural Language Proces...  \n2                                        [GCP, Azure]  \n3   [Cryptocurrency development, IoT, MQTT, Sensor...  \n4        [UI Design, Responsive Design, React Native]  \n..                                                ...  \n95                [GCP, Build Automation, Kubernetes]  \n96   [HTML, React, CSS, UI Design, Web Accessibility]  \n97                    [Agile Methodologies, Selenium]  \n98  [Troubleshooting, Active Directory, Security B...  \n99          [Microsoft SQL Server, RDBMS, MySQL, SQL]  \n\n[100 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_stories</th>\n      <th>skills</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>As a software developer at our company, I want...</td>\n      <td>[MQTT, IoT,  Sensor Integration,  Smart contra...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>As a software developer at our company, I want...</td>\n      <td>[Pandas, scikit-learn, Natural Language Proces...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>As a DevOps engineer at our company, I want to...</td>\n      <td>[GCP, Azure]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>As a software engineer at our cryptocurrency d...</td>\n      <td>[Cryptocurrency development, IoT, MQTT, Sensor...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>As a UI/UX designer and developer at our softw...</td>\n      <td>[UI Design, Responsive Design, React Native]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>As a DevOps engineer, I want to automate the b...</td>\n      <td>[GCP, Build Automation, Kubernetes]</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>As a web developer, I want to implement a user...</td>\n      <td>[HTML, React, CSS, UI Design, Web Accessibility]</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>As a QA engineer, I want to integrate Selenium...</td>\n      <td>[Agile Methodologies, Selenium]</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>As an IT administrator, I want to implement se...</td>\n      <td>[Troubleshooting, Active Directory, Security B...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>As a database developer, I want to optimize ou...</td>\n      <td>[Microsoft SQL Server, RDBMS, MySQL, SQL]</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_stories_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:12.728762500Z",
     "start_time": "2024-07-10T13:48:12.698638200Z"
    }
   },
   "id": "147b8e2ce09340e5"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "contras_df = pd.read_csv('truth.csv', index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:12.728762500Z",
     "start_time": "2024-07-10T13:48:12.713385900Z"
    }
   },
   "id": "ca7f6133a8f64dff"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Extract NaN skills for each column\n",
    "skills_nan = {col: contras_df.loc[contras_df[col].isna()].index.tolist() for col in contras_df.columns}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:12.738953700Z",
     "start_time": "2024-07-10T13:48:12.718246400Z"
    }
   },
   "id": "47016e54ed1b77bf"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Create a new DataFrame with the desired structure\n",
    "new_data = []\n",
    "for col, nan_indices in skills_nan.items():\n",
    "    #nan_indices = ', '.join(nan_indices)\n",
    "    new_data.append([col, nan_indices])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:12.738953700Z",
     "start_time": "2024-07-10T13:48:12.733188Z"
    }
   },
   "id": "123fe4e365a4bf62"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "contras_df = pd.DataFrame(new_data, columns=['user_stories', 'skills'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:12.745183500Z",
     "start_time": "2024-07-10T13:48:12.737955200Z"
    }
   },
   "id": "62791ad44eb80544"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "model_name = \"deberta\"\n",
    "if model_name == \"bart\":\n",
    "    model_dir = \"facebook/bart-large-mnli\"\n",
    "else:\n",
    "    model_dir = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:14.148126500Z",
     "start_time": "2024-07-10T13:48:12.742182400Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def get_new_tokens(sentences, vocabulary):\n",
    "    vocab_set = set(vocabulary)\n",
    "    cleaned_words = (re.sub(r\"[.'\\s\\n]+|('\\s)\", \"\", word).lower().strip() for sentence in sentences for word in\n",
    "                     sentence)\n",
    "    return [word for word in cleaned_words if word not in vocab_set and word]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:14.155119400Z",
     "start_time": "2024-07-10T13:48:14.150692700Z"
    }
   },
   "id": "7cdd7dc96762187c"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def word_count(word_list):\n",
    "    return Counter(word_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:14.155119400Z",
     "start_time": "2024-07-10T13:48:14.153202900Z"
    }
   },
   "id": "69437d4fecb1fa74"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def tokenize(data):\n",
    "    data['hypothesis'] = data['hypothesis'].astype(\"str\")\n",
    "    premises = []\n",
    "    for x in data['premise'].to_list():\n",
    "        premises.extend([item.strip() for item in x])\n",
    "    #data['premise'] = data['premise'].astype(\"str\")\n",
    "    sentences = data['hypothesis'].to_list() + premises\n",
    "    #sentences = [sentence.replace(\",\", \"\") for sentence in sentences]\n",
    "    \n",
    "    vocabulary = tokenizer.get_vocab().keys()\n",
    "    tokens_to_add = get_new_tokens(sentences, vocabulary)\n",
    "    words = word_count(tokens_to_add)\n",
    "    # Initialize an empty list to store new tokens + Loop through the words and their counts\n",
    "    new_tokens = []\n",
    "    for key, value in words.items():\n",
    "        if value > 10 and len(key) > 2:\n",
    "            new_tokens.append(key)\n",
    "    tokenizer.add_tokens(new_tokens)\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:14.161156900Z",
     "start_time": "2024-07-10T13:48:14.157119500Z"
    }
   },
   "id": "987ec13a62e57310"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def synth_to_nli(data, value):\n",
    "    data = data.copy()\n",
    "    data.rename(columns={'user_stories': 'hypothesis', 'skills': 'premise'}, inplace=True)\n",
    "    data['class'] = value\n",
    "    tokenize(data)\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:14.162666Z",
     "start_time": "2024-07-10T13:48:14.161661Z"
    }
   },
   "id": "dfe5d6d76115d004"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "if model_name == \"bart\":\n",
    "    df = synth_to_nli(user_stories_df, 2) # entailement\n",
    "    contras_df = synth_to_nli(contras_df, 0) # contradiction\n",
    "else:\n",
    "    df = synth_to_nli(user_stories_df, 0) # entailement\n",
    "    contras_df = synth_to_nli(contras_df, 2) # contradiction"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:15.130703300Z",
     "start_time": "2024-07-10T13:48:14.163665100Z"
    }
   },
   "id": "882a65f9d6e6bdab"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "df = df.explode('premise')\n",
    "contras_df = contras_df.explode('premise')\n",
    "contras_df = contras_df.sample(359)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:15.142075700Z",
     "start_time": "2024-07-10T13:48:15.130703300Z"
    }
   },
   "id": "7d7df2f4de5604d8"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "df = pd.concat([df, contras_df], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:15.148096800Z",
     "start_time": "2024-07-10T13:48:15.142075700Z"
    }
   },
   "id": "36333a41993d494c"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:15.154127300Z",
     "start_time": "2024-07-10T13:48:15.148096800Z"
    }
   },
   "id": "56668a2dbf9d633c"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            hypothesis              premise  \\\n0    As a software developer at our company, I want...                 MQTT   \n1    As a software developer at our company, I want...                  IoT   \n2    As a software developer at our company, I want...   Sensor Integration   \n3    As a software developer at our company, I want...      Smart contracts   \n4    As a software developer at our company, I want...               Pandas   \n..                                                 ...                  ...   \n713  As a software developer at our company, I want...  Wireless Networking   \n714  As a web developer, I want to ensure cross-bro...    Data Manipulation   \n715  As a software developer at our company, I want...              PyTorch   \n716  As an IT Project Manager overseeing the develo...          Data Mining   \n717  As a system administrator, I want to implement...  Blockchain security   \n\n     class  \n0        0  \n1        0  \n2        0  \n3        0  \n4        0  \n..     ...  \n713      2  \n714      2  \n715      2  \n716      2  \n717      2  \n\n[718 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hypothesis</th>\n      <th>premise</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>As a software developer at our company, I want...</td>\n      <td>MQTT</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>As a software developer at our company, I want...</td>\n      <td>IoT</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>As a software developer at our company, I want...</td>\n      <td>Sensor Integration</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>As a software developer at our company, I want...</td>\n      <td>Smart contracts</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>As a software developer at our company, I want...</td>\n      <td>Pandas</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>713</th>\n      <td>As a software developer at our company, I want...</td>\n      <td>Wireless Networking</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>714</th>\n      <td>As a web developer, I want to ensure cross-bro...</td>\n      <td>Data Manipulation</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>715</th>\n      <td>As a software developer at our company, I want...</td>\n      <td>PyTorch</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>716</th>\n      <td>As an IT Project Manager overseeing the develo...</td>\n      <td>Data Mining</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>717</th>\n      <td>As a system administrator, I want to implement...</td>\n      <td>Blockchain security</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>718 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:15.166055100Z",
     "start_time": "2024-07-10T13:48:15.151118400Z"
    }
   },
   "id": "ba15315a0f0e1485"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def shuffle_df(old_df: pd.DataFrame, cycles: int = 1) -> pd.DataFrame:\n",
    "    np.random.seed(42)\n",
    "    for i in range(cycles):\n",
    "        new_df = old_df.sample(frac=1).reset_index(drop=True)\n",
    "        return new_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:15.166055100Z",
     "start_time": "2024-07-10T13:48:15.158035400Z"
    }
   },
   "id": "10bb994e77f4286b"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Function to encode the dataset\n",
    "def encode_examples(examples):\n",
    "    encoding = tokenizer(examples['hypothesis'], examples['premise'], truncation=True)\n",
    "    encoding['labels'] = examples['class']\n",
    "    encoding[\"input_sentence\"] = tokenizer.batch_decode(encoding.input_ids)\n",
    "    return encoding"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:15.167060200Z",
     "start_time": "2024-07-10T13:48:15.162490500Z"
    }
   },
   "id": "c1b88512f2f82e66"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "test_size = 0.8"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:15.175573700Z",
     "start_time": "2024-07-10T13:48:15.163999600Z"
    }
   },
   "id": "396a164fe189e61c"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=test_size, random_state=42)\n",
    "train_shuffle_df = shuffle_df(train_data)\n",
    "test_shuffle_df = shuffle_df(test_data)\n",
    "\n",
    "# Create a Dataset object from the shuffled train DataFrame\n",
    "train = Dataset.from_pandas(train_shuffle_df)\n",
    "test = Dataset.from_pandas(test_shuffle_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:15.218515100Z",
     "start_time": "2024-07-10T13:48:15.168059900Z"
    }
   },
   "id": "116b8e05c088d0db"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/143 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4f5bd895fab436ba506b34c97260fc5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# Map the create_input_sequence function to the train and test datasets - This function encodes the data, adds labels, and generates input sentences\n",
    "train_dataset = train.map(encode_examples, batched=True, batch_size=1, remove_columns=[\"class\", \"premise\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:15.452144800Z",
     "start_time": "2024-07-10T13:48:15.203498100Z"
    }
   },
   "id": "bfcc70bafd3c84bd"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/575 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ff677dda0e74d80a1a66666efbb628e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = test.map(encode_examples, batched=True, batch_size=1, remove_columns=[\"class\", \"premise\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:16.116556700Z",
     "start_time": "2024-07-10T13:48:15.436765900Z"
    }
   },
   "id": "1c7972a0d58b6ecd"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from transformers import EvalPrediction\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    # Extracting predictions from EvalPrediction object\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    # Obtaining the predicted classes\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "\n",
    "    # Calculating the ratio of predictions equals to 2 (assumed label)\n",
    "    ratio = np.mean(preds == 2)\n",
    "\n",
    "    # Dictionary to store computed metrics\n",
    "    metric_result = {}\n",
    "\n",
    "    # Loading evaluation metrics\n",
    "    metric_f1 = load_metric(\"f1\", trust_remote_code=True)\n",
    "    metric_precision = load_metric(\"precision\", trust_remote_code=True)\n",
    "    metric_recall = load_metric(\"recall\", trust_remote_code=True)\n",
    "    metric_acc = load_metric(\"accuracy\", trust_remote_code=True)\n",
    "\n",
    "    # Computing various metrics\n",
    "    metric_result[\"accuracy\"] = metric_acc.compute(predictions=preds, references=p.label_ids)[\"accuracy\"]\n",
    "    metric_result[\"precision\"] = metric_precision.compute(predictions=preds, references=p.label_ids, average='macro')['precision']\n",
    "    metric_result[\"recall\"] = metric_recall.compute(predictions=preds, references=p.label_ids, average='macro')[\"recall\"]\n",
    "    metric_result[\"f1\"] = metric_f1.compute(predictions=preds, references=p.label_ids, average='macro')[\"f1\"]\n",
    "    metric_result[\"ratio\"] = ratio\n",
    "\n",
    "    return metric_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:16.121579700Z",
     "start_time": "2024-07-10T13:48:16.117555900Z"
    }
   },
   "id": "3c93a6f310cad0fe"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter deberta.embeddings.word_embeddings.weight: eingefroren\n",
      "Parameter deberta.embeddings.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.embeddings.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.0.attention.self.query_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.0.attention.self.query_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.0.attention.self.key_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.0.attention.self.key_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.0.attention.self.value_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.0.attention.self.value_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.0.attention.output.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.0.attention.output.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.0.attention.output.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.0.attention.output.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.0.intermediate.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.0.intermediate.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.0.output.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.0.output.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.0.output.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.0.output.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.1.attention.self.query_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.1.attention.self.query_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.1.attention.self.key_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.1.attention.self.key_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.1.attention.self.value_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.1.attention.self.value_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.1.attention.output.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.1.attention.output.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.1.attention.output.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.1.attention.output.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.1.intermediate.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.1.intermediate.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.1.output.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.1.output.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.1.output.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.1.output.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.2.attention.self.query_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.2.attention.self.query_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.2.attention.self.key_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.2.attention.self.key_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.2.attention.self.value_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.2.attention.self.value_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.2.attention.output.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.2.attention.output.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.2.attention.output.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.2.attention.output.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.2.intermediate.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.2.intermediate.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.2.output.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.2.output.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.2.output.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.2.output.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.3.attention.self.query_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.3.attention.self.query_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.3.attention.self.key_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.3.attention.self.key_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.3.attention.self.value_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.3.attention.self.value_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.3.attention.output.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.3.attention.output.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.3.attention.output.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.3.attention.output.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.3.intermediate.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.3.intermediate.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.3.output.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.3.output.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.3.output.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.3.output.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.4.attention.self.query_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.4.attention.self.query_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.4.attention.self.key_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.4.attention.self.key_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.4.attention.self.value_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.4.attention.self.value_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.4.attention.output.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.4.attention.output.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.4.attention.output.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.4.attention.output.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.4.intermediate.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.4.intermediate.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.4.output.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.4.output.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.4.output.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.4.output.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.5.attention.self.query_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.5.attention.self.query_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.5.attention.self.key_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.5.attention.self.key_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.5.attention.self.value_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.5.attention.self.value_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.5.attention.output.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.5.attention.output.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.5.attention.output.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.5.attention.output.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.5.intermediate.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.5.intermediate.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.5.output.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.5.output.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.5.output.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.5.output.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.6.attention.self.query_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.6.attention.self.query_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.6.attention.self.key_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.6.attention.self.key_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.6.attention.self.value_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.6.attention.self.value_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.6.attention.output.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.6.attention.output.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.6.attention.output.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.6.attention.output.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.6.intermediate.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.6.intermediate.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.6.output.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.6.output.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.6.output.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.6.output.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.7.attention.self.query_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.7.attention.self.query_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.7.attention.self.key_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.7.attention.self.key_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.7.attention.self.value_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.7.attention.self.value_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.7.attention.output.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.7.attention.output.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.7.attention.output.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.7.attention.output.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.7.intermediate.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.7.intermediate.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.7.output.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.7.output.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.7.output.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.7.output.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.8.attention.self.query_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.8.attention.self.query_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.8.attention.self.key_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.8.attention.self.key_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.8.attention.self.value_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.8.attention.self.value_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.8.attention.output.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.8.attention.output.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.8.attention.output.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.8.attention.output.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.8.intermediate.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.8.intermediate.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.8.output.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.8.output.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.8.output.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.8.output.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.9.attention.self.query_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.9.attention.self.query_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.9.attention.self.key_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.9.attention.self.key_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.9.attention.self.value_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.9.attention.self.value_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.9.attention.output.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.9.attention.output.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.9.attention.output.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.9.attention.output.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.9.intermediate.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.9.intermediate.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.9.output.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.9.output.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.9.output.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.9.output.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.10.attention.self.query_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.10.attention.self.query_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.10.attention.self.key_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.10.attention.self.key_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.10.attention.self.value_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.10.attention.self.value_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.10.attention.output.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.10.attention.output.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.10.attention.output.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.10.attention.output.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.10.intermediate.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.10.intermediate.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.10.output.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.10.output.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.10.output.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.10.output.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.11.attention.self.query_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.11.attention.self.query_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.11.attention.self.key_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.11.attention.self.key_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.11.attention.self.value_proj.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.11.attention.self.value_proj.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.11.attention.output.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.11.attention.output.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.11.attention.output.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.11.attention.output.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.11.intermediate.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.11.intermediate.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.11.output.dense.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.11.output.dense.bias: eingefroren\n",
      "Parameter deberta.encoder.layer.11.output.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.layer.11.output.LayerNorm.bias: eingefroren\n",
      "Parameter deberta.encoder.rel_embeddings.weight: eingefroren\n",
      "Parameter deberta.encoder.LayerNorm.weight: eingefroren\n",
      "Parameter deberta.encoder.LayerNorm.bias: eingefroren\n",
      "Parameter pooler.dense.weight: trainierbar\n",
      "Parameter pooler.dense.bias: trainierbar\n",
      "Parameter classifier.weight: trainierbar\n",
      "Parameter classifier.bias: trainierbar\n"
     ]
    }
   ],
   "source": [
    "# Einfrieren aller Parameter des Basismodells (Transformermodell)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Optional: ÃœberprÃ¼fen Sie, welche Parameter trainiert werden\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter {name}: {'trainierbar' if param.requires_grad else 'eingefroren'}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:16.128301600Z",
     "start_time": "2024-07-10T13:48:16.120578200Z"
    }
   },
   "id": "8b4210f7472eed9e"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()\n",
    "model.config.use_cache = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:16.137164500Z",
     "start_time": "2024-07-10T13:48:16.125302400Z"
    }
   },
   "id": "d73f1874d8dc8035"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "train_batch = 32\n",
    "eval_batch = 32\n",
    "lr = 2e-05\n",
    "eps = 3\n",
    "wd = 0.06\n",
    "warm_ratio = 0.1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:16.138165200Z",
     "start_time": "2024-07-10T13:48:16.133654600Z"
    }
   },
   "id": "58f99fae3764ac09"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"FinalRuns\",\n",
    "    num_train_epochs=eps,              # total number of training epochs\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=train_batch,   # batch size per device during training\n",
    "    per_device_eval_batch_size=eval_batch,    # batch size for evaluation\n",
    "    warmup_ratio=warm_ratio,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=wd,               # strength of weight decay\n",
    "    fp16=True                        # mixed precision training\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:16.185989500Z",
     "start_time": "2024-07-10T13:48:16.136164100Z"
    }
   },
   "id": "aa6edd377e20632b"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=False,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_steps=None,\neval_strategy=IntervalStrategy.NO,\nevaluation_strategy=None,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=1,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=HubStrategy.EVERY_SAVE,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=passive,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=FinalRuns\\runs\\Jul10_15-48-16_DESKTOP-968BNEJ,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=500,\nlogging_strategy=IntervalStrategy.STEPS,\nlr_scheduler_kwargs={},\nlr_scheduler_type=SchedulerType.LINEAR,\nmax_grad_norm=1.0,\nmax_steps=-1,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3,\noptim=OptimizerNames.ADAMW_TORCH,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=FinalRuns,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=32,\nper_device_train_batch_size=32,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=FinalRuns,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=True,\nsave_steps=500,\nsave_strategy=IntervalStrategy.STEPS,\nsave_total_limit=None,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_mps_device=False,\nwarmup_ratio=0.1,\nwarmup_steps=0,\nweight_decay=0.06,\n)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:16.192503200Z",
     "start_time": "2024-07-10T13:48:16.185989500Z"
    }
   },
   "id": "6b1f05c7b90e5859"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:16.501460100Z",
     "start_time": "2024-07-10T13:48:16.193503800Z"
    }
   },
   "id": "868904be129ec2a8"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Thesis\\venv\\Lib\\site-packages\\torch\\utils\\checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 2/15 : < :, Epoch 0.20/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=15, training_loss=1.9950833638509116, metrics={'train_runtime': 2.628, 'train_samples_per_second': 163.241, 'train_steps_per_second': 5.708, 'total_flos': 14990025231090.0, 'train_loss': 1.9950833638509116, 'epoch': 3.0})"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:19.262802200Z",
     "start_time": "2024-07-10T13:48:16.502458300Z"
    }
   },
   "id": "f0ce14d92ab4883a"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "592899"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.get_num_trainable_parameters() #6 Epochen: 1052675 vs. 407344131"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:19.269463600Z",
     "start_time": "2024-07-10T13:48:19.263802500Z"
    }
   },
   "id": "ada1a50f70ade173"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/18 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Coco\\AppData\\Local\\Temp\\ipykernel_31436\\1772683132.py:17: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric_f1 = load_metric(\"f1\", trust_remote_code=True)\n",
      "D:\\Thesis\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'eval_loss': 2.2735488414764404,\n 'eval_accuracy': 0.40869565217391307,\n 'eval_precision': 0.5517069772071265,\n 'eval_recall': 0.2710828796128251,\n 'eval_f1': 0.34664060667050584,\n 'eval_ratio': 0.11826086956521739,\n 'eval_runtime': 3.0353,\n 'eval_samples_per_second': 189.44,\n 'eval_steps_per_second': 5.93,\n 'epoch': 3.0}"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:22.313409800Z",
     "start_time": "2024-07-10T13:48:19.267956200Z"
    }
   },
   "id": "e090799b0380d48b"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "DebertaV2ForSequenceClassification(\n  (deberta): DebertaV2Model(\n    (embeddings): DebertaV2Embeddings(\n      (word_embeddings): Embedding(128001, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n      (dropout): StableDropout()\n    )\n    (encoder): DebertaV2Encoder(\n      (layer): ModuleList(\n        (0-11): 12 x DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n      )\n      (rel_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): StableDropout()\n  )\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n  (dropout): StableDropout()\n)"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:22.319974700Z",
     "start_time": "2024-07-10T13:48:22.314961800Z"
    }
   },
   "id": "3490ff0933eeb0a1"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "trainer.save_model(f\"FinalRuns_PreTrained/{model_name}_{eps}_{lr}_{train_batch}{eval_batch}_{warm_ratio}_{wd}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:23.827355200Z",
     "start_time": "2024-07-10T13:48:22.316470100Z"
    }
   },
   "id": "f5c6670134492f59"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "#model.save_pretrained(f\"test_trainer_Trainer_{model_name}/{datetime.now().strftime('%Y%m%d-%H%M%S')}\",from_pt=True)\n",
    "#model.save_pretrained(f\"FinalRuns_PreTrained_{model_name}/{eps}_{lr}_{train_batch}{eval_batch}_{warm_ratio}_{wd}\",from_pt=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:27.947933900Z",
     "start_time": "2024-07-10T13:48:23.828358800Z"
    }
   },
   "id": "ee79980b6b0b609e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create Pipeline with the new model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c08dac08f8aae47"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# Create new pipeline object with our fine-tuned model and tokenizer\n",
    "model.config.use_cache = True\n",
    "classifier_after = pipeline('zero-shot-classification', model=model, tokenizer=tokenizer, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:48:27.954559800Z",
     "start_time": "2024-07-10T13:48:27.949970600Z"
    }
   },
   "id": "1b36bf38181d6364"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "hypothesis_template = \"To resolve this issue the skill {} is needed.\"\n",
    "\n",
    "after_results = classifier_after(user_stories, labels, multi_label=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:52:14.460380100Z",
     "start_time": "2024-07-10T13:48:27.951978900Z"
    }
   },
   "id": "a29189341f44795f"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "\n",
    "split = str(test_size).replace(\".\",\"\") + f\"_freeze1_{eps}_{lr}_{train_batch}{eval_batch}_{warm_ratio}_{wd}\"\n",
    "\n",
    "#split = str(test_size).replace(\".\",\"\") + f\"_default\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:52:14.466562400Z",
     "start_time": "2024-07-10T13:52:14.463050300Z"
    }
   },
   "id": "8721406e005b6138"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "with open(f\"output_txt/{model_name}_{split}.txt\", 'w') as f:\n",
    "    for story, result in zip(user_stories, after_results):\n",
    "        f.write(f\"Story: {story}\\n\")\n",
    "        for label, score in zip(result['labels'], result['scores']):\n",
    "            f.write(f\"- {label}: {score:.2f}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:52:14.494065700Z",
     "start_time": "2024-07-10T13:52:14.465562600Z"
    }
   },
   "id": "e937c71119f19bbe"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Thesis\\FineTuning\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "file_dir = os.getcwd()\n",
    "#dir = os.path.abspath(\"\")\n",
    "csv = Conv.CsvConverter(os.path.join(file_dir, 'output_txt',f'{model_name}_{split}.txt'),\n",
    "                        os.path.join(file_dir, 'output_csv', f'{model_name}_{split}.csv'),\n",
    "                        'Story')\n",
    "csv.convert()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:52:14.561167800Z",
     "start_time": "2024-07-10T13:52:14.495066900Z"
    }
   },
   "id": "13d439cfa2b1a884"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---_08_freeze1_3_2e-05_3232_0.1_0.06---\n",
      "\n",
      "---DEBERTA---\n",
      "  Threshold    Label Density    Subset Accuracy    Recall    F1 Score    F-Beta Score    Hamming Loss    ROC AUC    Jaccard Loss\n",
      "-----------  ---------------  -----------------  --------  ----------  --------------  --------------  ---------  --------------\n",
      "       1                0.13               0       0.0143      0.0228          0.0168          0.0281     0.5068          0.0143\n",
      "       0.95             2.66               0.12    0.4698      0.4825          0.4697          0.0235     0.7307          0.3883\n",
      "       0.9              3.62               0.16    0.6501      0.5968          0.6182          0.0221     0.8193          0.4934\n",
      "       0.8              4.59               0.12    0.7249      0.605           0.6606          0.0252     0.854           0.4915\n",
      "       0.5              8.9                0       0.8072      0.4687          0.607           0.054      0.879           0.3271\n",
      "Differences:\n",
      "  Threshold    Label Density    Subset Accuracy    Recall    F1 Score    F-Beta Score    Hamming Loss    ROC AUC    Jaccard Loss\n",
      "-----------  ---------------  -----------------  --------  ----------  --------------  --------------  ---------  --------------\n",
      "          0             0.04               0       0.0025      0.004           0.003           0.0001     0.0011          0.0025\n",
      "          0            -0.01               0       0.0017      0.0022          0.0019         -0.0001     0.0009          0.0031\n",
      "          0            -0.04              -0.01   -0.0042     -0.0025         -0.0035          0         -0.002          -0.003\n",
      "          0            -0.08               0.02   -0.0025      0.0038          0.0004         -0.0004    -0.001           0.0072\n",
      "          0            -1.38               0      -0.0033      0.0312          0.0273         -0.0106     0.0038          0.0268\n"
     ]
    }
   ],
   "source": [
    "import MetricsGenerator as Metrics\n",
    "dir = os.getcwd()\n",
    "end_dir = os.path.join(dir, \"output_csv\")\n",
    "if model_name == \"bart\":\n",
    "    metrics = Metrics.MetricsGenerator(f\"_{split}\", dir, end_dir, False, True, False).main()\n",
    "else:\n",
    "    metrics = Metrics.MetricsGenerator(f\"_{split}\", dir, end_dir, False, False, True).main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T13:52:14.768149500Z",
     "start_time": "2024-07-10T13:52:14.532623800Z"
    }
   },
   "id": "7aa1450656a492eb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
